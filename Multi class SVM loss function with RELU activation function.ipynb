{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c9fa61ad",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter the number of layers: 4\n",
      "Enter the number of neurons in layer 1: 2\n",
      "Enter the number of neurons in layer 2: 3\n",
      "Enter the number of neurons in layer 3: 3\n",
      "Enter the number of neurons in layer 4: 2\n",
      "[[0.5        0.5       ]\n",
      " [0.5000019  0.49999812]\n",
      " [0.50000525 0.49999478]\n",
      " [0.5000087  0.49999133]\n",
      " [0.5000118  0.49998823]\n",
      " [0.5000058  0.49999422]\n",
      " [0.50001776 0.49998224]\n",
      " [0.5000177  0.49998233]\n",
      " [0.50002164 0.49997836]\n",
      " [0.50002676 0.49997327]\n",
      " [0.5000296  0.4999704 ]\n",
      " [0.50002605 0.49997398]\n",
      " [0.50003284 0.49996713]\n",
      " [0.500038   0.49996194]\n",
      " [0.5000376  0.49996242]\n",
      " [0.50003934 0.49996066]\n",
      " [0.5000161  0.49998394]\n",
      " [0.50004613 0.4999539 ]\n",
      " [0.50003713 0.4999629 ]\n",
      " [0.500054   0.49994603]\n",
      " [0.50005376 0.49994627]\n",
      " [0.5000157  0.49998432]\n",
      " [0.50000226 0.49999774]\n",
      " [0.50004864 0.49995136]\n",
      " [0.50002295 0.49997705]\n",
      " [0.50006104 0.49993896]\n",
      " [0.5000031  0.49999687]\n",
      " [0.50000453 0.49999544]\n",
      " [0.5000278  0.49997222]\n",
      " [0.5000307  0.49996927]\n",
      " [0.50001234 0.4999877 ]\n",
      " [0.5000212  0.49997875]\n",
      " [0.5        0.5       ]\n",
      " [0.5000351  0.4999649 ]\n",
      " [0.50002074 0.49997926]\n",
      " [0.5000354  0.49996462]\n",
      " [0.50005025 0.49994978]\n",
      " [0.50005203 0.499948  ]\n",
      " [0.5000396  0.49996045]\n",
      " [0.5000455  0.49995455]\n",
      " [0.5000364  0.49996355]\n",
      " [0.5000335  0.4999665 ]\n",
      " [0.50003225 0.49996775]\n",
      " [0.50003165 0.49996838]\n",
      " [0.50006074 0.49993923]\n",
      " [0.50006324 0.4999368 ]\n",
      " [0.5000605  0.4999395 ]\n",
      " [0.50004596 0.49995407]\n",
      " [0.50006366 0.49993637]\n",
      " [0.50006175 0.49993825]\n",
      " [0.50006866 0.49993137]\n",
      " [0.50003564 0.49996436]\n",
      " [0.5000593  0.49994072]\n",
      " [0.50006926 0.49993077]\n",
      " [0.5000303  0.49996972]\n",
      " [0.5000029  0.4999971 ]\n",
      " [0.50001    0.49999   ]\n",
      " [0.5000013  0.4999987 ]\n",
      " [0.5000237  0.49997628]\n",
      " [0.5000023  0.49999768]\n",
      " [0.50000745 0.49999252]\n",
      " [0.50001466 0.49998534]\n",
      " [0.5        0.5       ]\n",
      " [0.5000297  0.49997035]\n",
      " [0.5001157  0.4998843 ]\n",
      " [0.50008655 0.4999134 ]\n",
      " [0.5        0.5       ]\n",
      " [0.5001776  0.49982235]\n",
      " [0.50009954 0.49990043]\n",
      " [0.5001826  0.4998174 ]\n",
      " [0.5002083  0.49979168]\n",
      " [0.5002056  0.49979442]\n",
      " [0.50019985 0.49980015]\n",
      " [0.5001641  0.49983594]\n",
      " [0.5002158  0.49978423]\n",
      " [0.500217   0.49978298]\n",
      " [0.50022036 0.49977967]\n",
      " [0.5002293  0.49977073]\n",
      " [0.500225   0.49977502]\n",
      " [0.50020224 0.49979773]\n",
      " [0.5002381  0.49976185]\n",
      " [0.5000847  0.4999153 ]\n",
      " [0.50011355 0.49988645]\n",
      " [0.5002446  0.49975538]\n",
      " [0.5000158  0.49998423]\n",
      " [0.5000508  0.4999492 ]\n",
      " [0.5000218  0.4999782 ]\n",
      " [0.5000738  0.4999262 ]\n",
      " [0.5001605  0.49983948]\n",
      " [0.5000513  0.4999487 ]\n",
      " [0.50002295 0.49997708]\n",
      " [0.50008327 0.49991676]\n",
      " [0.5000385  0.49996153]\n",
      " [0.5000927  0.4999073 ]\n",
      " [0.50007224 0.49992773]\n",
      " [0.5001008  0.4998992 ]\n",
      " [0.50007707 0.49992296]\n",
      " [0.50013644 0.49986356]\n",
      " [0.50010514 0.49989486]\n",
      " [0.5001245  0.4998755 ]\n",
      " [0.5        0.5       ]\n",
      " [0.5000005  0.49999955]\n",
      " [0.5000013  0.49999872]\n",
      " [0.5000042  0.4999958 ]\n",
      " [0.50000376 0.49999627]\n",
      " [0.50000453 0.49999547]\n",
      " [0.50000817 0.49999186]\n",
      " [0.5000093  0.49999067]\n",
      " [0.50000393 0.49999607]\n",
      " [0.500006   0.49999398]\n",
      " [0.50000226 0.49999776]\n",
      " [0.5000087  0.49999133]\n",
      " [0.50001675 0.49998322]\n",
      " [0.5000033  0.49999675]\n",
      " [0.500016   0.49998406]\n",
      " [0.500004   0.49999598]\n",
      " [0.5        0.5       ]\n",
      " [0.5000116  0.4999884 ]\n",
      " [0.5        0.5       ]\n",
      " [0.500011   0.49998897]\n",
      " [0.50000143 0.49999854]\n",
      " [0.50001633 0.49998367]\n",
      " [0.5000122  0.4999878 ]\n",
      " [0.50004923 0.49995077]\n",
      " [0.50000036 0.49999964]\n",
      " [0.5000196  0.49998042]\n",
      " [0.5000172  0.49998277]\n",
      " [0.50008    0.49992004]\n",
      " [0.50006926 0.49993077]\n",
      " [0.50007015 0.49992982]\n",
      " [0.50003976 0.49996027]\n",
      " [0.5000866  0.4999134 ]\n",
      " [0.50006217 0.49993783]\n",
      " [0.5000903  0.4999097 ]\n",
      " [0.5000813  0.49991873]\n",
      " [0.5001035  0.4998965 ]\n",
      " [0.5001057  0.49989432]\n",
      " [0.5001094  0.49989063]\n",
      " [0.5001087  0.49989128]\n",
      " [0.5001086  0.4998914 ]\n",
      " [0.5001067  0.49989328]\n",
      " [0.5001003  0.49989963]\n",
      " [0.50010526 0.49989474]\n",
      " [0.5000757  0.49992427]\n",
      " [0.5000158  0.49998423]\n",
      " [0.50003314 0.49996686]\n",
      " [0.5001243  0.49987578]\n",
      " [0.5        0.5       ]\n",
      " [0.50012964 0.49987042]\n",
      " [0.50007874 0.49992126]\n",
      " [0.500037   0.49996296]\n",
      " [0.50004226 0.49995774]\n",
      " [0.5000598  0.4999402 ]\n",
      " [0.5000515  0.49994853]\n",
      " [0.5000021  0.49999794]\n",
      " [0.5000051  0.49999487]\n",
      " [0.50005877 0.49994126]\n",
      " [0.50000644 0.49999356]\n",
      " [0.5        0.5       ]\n",
      " [0.50002944 0.4999706 ]\n",
      " [0.50003546 0.49996457]\n",
      " [0.50008446 0.49991554]\n",
      " [0.5000853  0.49991474]\n",
      " [0.50007594 0.49992406]\n",
      " [0.50004107 0.49995893]\n",
      " [0.5000914  0.4999086 ]\n",
      " [0.50006586 0.49993417]\n",
      " [0.50005454 0.49994546]\n",
      " [0.5000833  0.4999167 ]\n",
      " [0.50009555 0.49990445]\n",
      " [0.50008225 0.49991778]\n",
      " [0.5000927  0.49990728]\n",
      " [0.5000705  0.49992952]\n",
      " [0.50010216 0.49989778]\n",
      " [0.50010407 0.49989587]\n",
      " [0.50005186 0.49994814]\n",
      " [0.50010127 0.49989867]\n",
      " [0.5000959  0.4999041 ]\n",
      " [0.5000811  0.49991888]\n",
      " [0.50004643 0.4999536 ]\n",
      " [0.50005674 0.49994323]\n",
      " [0.50009745 0.49990255]\n",
      " [0.5000515  0.49994853]\n",
      " [0.50011075 0.49988925]\n",
      " [0.50008106 0.49991897]\n",
      " [0.50007415 0.49992588]\n",
      " [0.50003165 0.49996838]\n",
      " [0.500088   0.499912  ]\n",
      " [0.50001353 0.49998644]\n",
      " [0.5002549  0.49974507]\n",
      " [0.5        0.5       ]\n",
      " [0.500205   0.49979496]\n",
      " [0.50019765 0.49980235]\n",
      " [0.500093   0.499907  ]\n",
      " [0.5002689  0.4997311 ]\n",
      " [0.5002444  0.49975562]\n",
      " [0.5002856  0.49971443]\n",
      " [0.5002846  0.4997154 ]\n",
      " [0.50016314 0.4998369 ]\n",
      " [0.5002382  0.4997618 ]\n",
      " [0.5        0.5       ]\n",
      " [0.500003   0.49999702]\n",
      " [0.5000045  0.49999556]\n",
      " [0.5000074  0.49999258]\n",
      " [0.5000092  0.49999085]\n",
      " [0.500014   0.49998596]\n",
      " [0.5000152  0.49998483]\n",
      " [0.5000199  0.4999801 ]\n",
      " [0.500014   0.499986  ]\n",
      " [0.50001776 0.4999822 ]\n",
      " [0.50000226 0.49999776]\n",
      " [0.5000092  0.49999085]\n",
      " [0.5        0.5       ]\n",
      " [0.50001806 0.4999819 ]\n",
      " [0.50002474 0.49997526]\n",
      " [0.5000106  0.49998936]\n",
      " [0.5        0.5       ]\n",
      " [0.50000584 0.4999942 ]\n",
      " [0.5000243  0.4999757 ]\n",
      " [0.50000626 0.49999374]\n",
      " [0.50000066 0.49999937]\n",
      " [0.50000834 0.49999163]\n",
      " [0.50001    0.49999002]\n",
      " [0.5000254  0.4999746 ]\n",
      " [0.5        0.5       ]\n",
      " [0.5000275  0.49997255]\n",
      " [0.5000316  0.49996838]\n",
      " [0.50003517 0.49996486]\n",
      " [0.50003004 0.49996993]\n",
      " [0.50003725 0.49996278]\n",
      " [0.50002575 0.49997422]\n",
      " [0.500041   0.499959  ]\n",
      " [0.5000434  0.49995664]\n",
      " [0.5000442  0.49995577]\n",
      " [0.5000445  0.4999555 ]\n",
      " [0.5000368  0.49996325]\n",
      " [0.50001514 0.4999849 ]\n",
      " [0.50004494 0.4999551 ]\n",
      " [0.500034   0.49996606]\n",
      " [0.5000226  0.49997744]\n",
      " [0.50004965 0.49995032]\n",
      " [0.50004226 0.49995777]\n",
      " [0.50003046 0.49996954]\n",
      " [0.50003004 0.49996993]\n",
      " [0.5000247  0.49997532]\n",
      " [0.5000563  0.4999437 ]\n",
      " [0.5000623  0.49993774]\n",
      " [0.5000716  0.49992844]\n",
      " [0.5000159  0.49998412]\n",
      " [0.5000327  0.49996728]\n",
      " [0.50007915 0.49992087]\n",
      " [0.5000171  0.49998286]\n",
      " [0.5000839  0.49991608]\n",
      " [0.5000677  0.49993232]\n",
      " [0.5001395  0.49986053]\n",
      " [0.50014967 0.49985033]\n",
      " [0.5000862  0.49991384]\n",
      " [0.50005263 0.49994737]\n",
      " [0.50005376 0.49994627]\n",
      " [0.5001754  0.49982458]\n",
      " [0.5001172  0.49988276]\n",
      " [0.50016636 0.4998336 ]\n",
      " [0.500173   0.499827  ]\n",
      " [0.5001876  0.49981242]\n",
      " [0.50012934 0.49987066]\n",
      " [0.50018257 0.49981743]\n",
      " [0.5001614  0.49983856]\n",
      " [0.500176   0.49982402]\n",
      " [0.50018716 0.49981287]\n",
      " [0.50015634 0.4998437 ]\n",
      " [0.5001153  0.4998847 ]\n",
      " [0.5001818  0.49981824]\n",
      " [0.5000305  0.49996948]\n",
      " [0.50005716 0.4999428 ]\n",
      " [0.50014514 0.49985486]\n",
      " [0.5001006  0.49989936]\n",
      " [0.5        0.5       ]\n",
      " [0.50002426 0.49997574]\n",
      " [0.50019896 0.499801  ]\n",
      " [0.50009733 0.4999026 ]\n",
      " [0.5000091  0.4999909 ]\n",
      " [0.5000774  0.49992254]\n",
      " [0.5        0.5       ]\n",
      " [0.50010914 0.49989086]\n",
      " [0.5000746  0.4999254 ]\n",
      " [0.500097   0.49990302]\n",
      " [0.50002635 0.49997362]\n",
      " [0.5001215  0.4998785 ]\n",
      " [0.5001189  0.49988106]\n",
      " [0.5001243  0.49987578]\n",
      " [0.50009364 0.49990636]\n",
      " [0.5001082  0.4998918 ]\n",
      " [0.50006855 0.49993145]\n",
      " [0.500104   0.49989593]\n",
      " [0.5001317  0.49986827]\n",
      " [0.50010467 0.49989533]\n",
      " [0.50013155 0.4998685 ]\n",
      " [0.50011456 0.49988538]\n",
      " [0.5001356  0.49986446]\n",
      " [0.5001067  0.49989325]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "np.random.seed(0)\n",
    "import nnfs\n",
    "from nnfs.datasets import spiral_data\n",
    "\n",
    "nnfs.init()\n",
    "\n",
    "class LayerDense:\n",
    "    def __init__(self, n_inputs, n_neurons):\n",
    "        self.weights = 0.10 * np.random.randn(n_inputs, n_neurons)\n",
    "        self.biases = np.zeros((1, n_neurons))\n",
    "    def forward(self, inputs):\n",
    "        self.output = np.dot(inputs, self.weights) + self.biases\n",
    "\n",
    "class ActivationReLU:  \n",
    "    def forward(self, inputs):\n",
    "        self.output = np.maximum(0, inputs)\n",
    "        \n",
    "class ActivationSoftmax:\n",
    "    def forward(self, inputs):\n",
    "        exp_values = np.exp(inputs - np.max(inputs, axis=1, keepdims=True))\n",
    "        probabilities = exp_values / np.sum(exp_values, axis=1, keepdims=True)\n",
    "        self.output = probabilities\n",
    "\n",
    "def create_network(layer_sizes):\n",
    "    network = []\n",
    "    for i in range(1, len(layer_sizes)):\n",
    "        network.append(LayerDense(layer_sizes[i-1], layer_sizes[i]))\n",
    "        if i < len(layer_sizes) - 1:\n",
    "            network.append(ActivationReLU())\n",
    "        else:\n",
    "            network.append(ActivationSoftmax())\n",
    "    return network\n",
    "\n",
    "def forward(network, X):\n",
    "    for layer in network:\n",
    "        layer.forward(X)\n",
    "        X = layer.output\n",
    "    return X\n",
    "\n",
    "num_layers = int(input(\"Enter the number of layers: \"))\n",
    "layer_neurons = []\n",
    "for i in range(num_layers):\n",
    "    neurons = int(input(f\"Enter the number of neurons in layer {i+1}: \"))\n",
    "    layer_neurons.append(neurons)\n",
    "\n",
    "X, y = spiral_data(samples=100, classes=3)        \n",
    "\n",
    "network = create_network(layer_neurons)\n",
    "output = forward(network, X)\n",
    "\n",
    "print(output)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4043f83a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter the number of layers: 4\n",
      "Enter the number of neurons in layer 1: 2\n",
      "Enter the number of neurons in layer 2: 3\n",
      "Enter the number of neurons in layer 3: 3\n",
      "Enter the number of neurons in layer 4: 2\n",
      "[[ 0.00000000e+00  0.00000000e+00]\n",
      " [-1.31784600e-06 -8.83766279e-06]\n",
      " [-3.66939980e-06 -2.46075178e-05]\n",
      " [-6.09072640e-06 -4.08452761e-05]\n",
      " [-8.25740062e-06 -5.53753052e-05]\n",
      " [-4.05061337e-06 -2.71639892e-05]\n",
      " [-1.24527905e-05 -8.35101819e-05]\n",
      " [-1.24018197e-05 -8.31683647e-05]\n",
      " [-1.51646382e-05 -1.01696220e-04]\n",
      " [-1.87359601e-05 -1.25646009e-04]\n",
      " [-2.07569210e-05 -1.39198863e-04]\n",
      " [-1.82503318e-05 -1.22389320e-04]\n",
      " [-2.30339156e-05 -1.54468711e-04]\n",
      " [-2.66732677e-05 -1.78874732e-04]\n",
      " [-2.63487673e-05 -1.76698581e-04]\n",
      " [-2.75792663e-05 -1.84950477e-04]\n",
      " [-1.12556845e-05 -7.54822177e-05]\n",
      " [-3.23173153e-05 -2.16724497e-04]\n",
      " [-2.60087108e-05 -1.74418106e-04]\n",
      " [-3.78505247e-05 -2.53830978e-04]\n",
      " [-3.76852986e-05 -2.52722966e-04]\n",
      " [-1.09913281e-05 -7.37094088e-05]\n",
      " [-1.58540763e-06 -1.06319694e-05]\n",
      " [-3.40932202e-05 -2.28633988e-04]\n",
      " [-1.60861855e-05 -1.07876251e-04]\n",
      " [-4.27937048e-05 -2.86980649e-04]\n",
      " [-2.17802562e-06 -1.46061493e-05]\n",
      " [-3.18369416e-06 -2.13503063e-05]\n",
      " [-1.94754793e-05 -1.30605331e-04]\n",
      " [-2.15268028e-05 -1.44361809e-04]\n",
      " [-8.62639808e-06 -5.78498511e-05]\n",
      " [-1.48848412e-05 -9.98198593e-05]\n",
      " [ 0.00000000e+00  0.00000000e+00]\n",
      " [-2.46116251e-05 -1.65049059e-04]\n",
      " [-1.45392723e-05 -9.75024232e-05]\n",
      " [-2.48014712e-05 -1.66322192e-04]\n",
      " [-3.52011484e-05 -2.36063919e-04]\n",
      " [-3.64571169e-05 -2.44486611e-04]\n",
      " [-2.77272393e-05 -1.85942801e-04]\n",
      " [-3.18659550e-05 -2.13697640e-04]\n",
      " [-2.55416435e-05 -1.71285894e-04]\n",
      " [-2.34783329e-05 -1.57449031e-04]\n",
      " [-2.26096199e-05 -1.51623331e-04]\n",
      " [-2.21783375e-05 -1.48731080e-04]\n",
      " [-4.25900434e-05 -2.85614893e-04]\n",
      " [-4.43126628e-05 -2.97167018e-04]\n",
      " [-4.24182399e-05 -2.84462760e-04]\n",
      " [-3.22043306e-05 -2.15966822e-04]\n",
      " [-4.46128615e-05 -2.99180188e-04]\n",
      " [-4.32961715e-05 -2.90350290e-04]\n",
      " [-4.81254465e-05 -3.22736072e-04]\n",
      " [-2.49886998e-05 -1.67577775e-04]\n",
      " [-4.15606264e-05 -2.78711464e-04]\n",
      " [-4.85349628e-05 -3.25482368e-04]\n",
      " [-2.12236901e-05 -1.42329081e-04]\n",
      " [-2.03874924e-06 -1.36721428e-05]\n",
      " [-7.01700765e-06 -4.70570521e-05]\n",
      " [-9.23279117e-07 -6.19164121e-06]\n",
      " [-1.66254522e-05 -1.11492649e-04]\n",
      " [-1.63152833e-06 -1.09412613e-05]\n",
      " [-5.23268409e-06 -3.50911214e-05]\n",
      " [-1.02762078e-05 -6.89137087e-05]\n",
      " [ 0.00000000e+00  0.00000000e+00]\n",
      " [-2.08016208e-05 -1.39498632e-04]\n",
      " [-8.10991914e-05 -5.43862698e-04]\n",
      " [-6.06901594e-05 -4.06996842e-04]\n",
      " [ 0.00000000e+00  0.00000000e+00]\n",
      " [-1.24522048e-04 -8.35062587e-04]\n",
      " [-6.97908981e-05 -4.68027662e-04]\n",
      " [-1.28015497e-04 -8.58490064e-04]\n",
      " [-1.46029153e-04 -9.79292206e-04]\n",
      " [-1.44118632e-04 -9.66480002e-04]\n",
      " [-1.40099219e-04 -9.39525256e-04]\n",
      " [-1.15015959e-04 -7.71313382e-04]\n",
      " [-1.51271699e-04 -1.01444952e-03]\n",
      " [-1.52132969e-04 -1.02022535e-03]\n",
      " [-1.54456910e-04 -1.03580998e-03]\n",
      " [-1.60717798e-04 -1.07779645e-03]\n",
      " [-1.57718358e-04 -1.05768174e-03]\n",
      " [-1.41784127e-04 -9.50824528e-04]\n",
      " [-1.66944155e-04 -1.11955125e-03]\n",
      " [-5.93790828e-05 -3.98204575e-04]\n",
      " [-7.95955930e-05 -5.33779326e-04]\n",
      " [-1.71474821e-04 -1.14993448e-03]\n",
      " [-1.10563997e-05 -7.41457916e-05]\n",
      " [-3.56084238e-05 -2.38795154e-04]\n",
      " [-1.52803041e-05 -1.02471888e-04]\n",
      " [-5.17299413e-05 -3.46908346e-04]\n",
      " [-1.12516587e-04 -7.54552195e-04]\n",
      " [-3.59535952e-05 -2.41109912e-04]\n",
      " [-1.60804066e-05 -1.07837492e-04]\n",
      " [-5.83687179e-05 -3.91428912e-04]\n",
      " [-2.69836564e-05 -1.80956238e-04]\n",
      " [-6.49719950e-05 -4.35711438e-04]\n",
      " [-5.06536126e-05 -3.39690305e-04]\n",
      " [-7.06475403e-05 -4.73772467e-04]\n",
      " [-5.40158107e-05 -3.62237712e-04]\n",
      " [-9.56401709e-05 -6.41376595e-04]\n",
      " [-7.37102164e-05 -4.94311214e-04]\n",
      " [-8.72784585e-05 -5.85301779e-04]\n",
      " [ 0.00000000e+00  0.00000000e+00]\n",
      " [-3.21473976e-07 -2.15585032e-06]\n",
      " [-8.96264908e-07 -6.01047986e-06]\n",
      " [-2.93694370e-06 -1.96955625e-05]\n",
      " [-2.60835986e-06 -1.74920333e-05]\n",
      " [-3.17046624e-06 -2.12615978e-05]\n",
      " [-5.70857173e-06 -3.82824910e-05]\n",
      " [-6.52571862e-06 -4.37623967e-05]\n",
      " [-2.76071069e-06 -1.85137178e-05]\n",
      " [-4.21928917e-06 -2.82951532e-05]\n",
      " [-1.57303418e-06 -1.05489908e-05]\n",
      " [-6.07773700e-06 -4.07581683e-05]\n",
      " [-1.17564923e-05 -7.88407124e-05]\n",
      " [-2.27490614e-06 -1.52558441e-05]\n",
      " [-1.11912041e-05 -7.50498075e-05]\n",
      " [-2.81088523e-06 -1.88501963e-05]\n",
      " [ 0.00000000e+00  0.00000000e+00]\n",
      " [-8.13456336e-06 -5.45515359e-05]\n",
      " [ 0.00000000e+00  0.00000000e+00]\n",
      " [-7.72652311e-06 -5.18151646e-05]\n",
      " [-1.00931447e-06 -6.76860600e-06]\n",
      " [-1.14538925e-05 -7.68114260e-05]\n",
      " [-8.54280916e-06 -5.72892932e-05]\n",
      " [-3.45156259e-05 -2.31466707e-04]\n",
      " [-2.50423625e-07 -1.67937640e-06]\n",
      " [-1.37288889e-05 -9.20678795e-05]\n",
      " [-1.20800742e-05 -8.10106940e-05]\n",
      " [-5.60638036e-05 -3.75971838e-04]\n",
      " [-4.85495038e-05 -3.25579866e-04]\n",
      " [-4.92000399e-05 -3.29942472e-04]\n",
      " [-2.78647567e-05 -1.86865014e-04]\n",
      " [-6.06985814e-05 -4.07053303e-04]\n",
      " [-4.35896436e-05 -2.92318349e-04]\n",
      " [-6.32941956e-05 -4.24459868e-04]\n",
      " [-5.69882322e-05 -3.82171187e-04]\n",
      " [-7.25507925e-05 -4.86535922e-04]\n",
      " [-7.40724645e-05 -4.96740511e-04]\n",
      " [-7.66662488e-05 -5.14134765e-04]\n",
      " [-7.62070267e-05 -5.11055172e-04]\n",
      " [-7.61323026e-05 -5.10554004e-04]\n",
      " [-7.48118182e-05 -5.01698698e-04]\n",
      " [-7.03444312e-05 -4.71739768e-04]\n",
      " [-7.37802475e-05 -4.94780834e-04]\n",
      " [-5.30829711e-05 -3.55981960e-04]\n",
      " [-1.10603833e-05 -7.41725016e-05]\n",
      " [-2.32335351e-05 -1.55807385e-04]\n",
      " [-8.70825897e-05 -5.83988207e-04]\n",
      " [ 0.00000000e+00  0.00000000e+00]\n",
      " [-9.08486109e-05 -6.09243696e-04]\n",
      " [-5.52020720e-05 -3.70192924e-04]\n",
      " [-2.59558219e-05 -1.74063432e-04]\n",
      " [-2.96295293e-05 -1.98699840e-04]\n",
      " [-4.19204589e-05 -2.81124550e-04]\n",
      " [-3.60888625e-05 -2.42017035e-04]\n",
      " [-1.43848456e-06 -9.64668197e-06]\n",
      " [-3.59826367e-06 -2.41304679e-05]\n",
      " [-4.11863512e-05 -2.76201521e-04]\n",
      " [-4.51076767e-06 -3.02498484e-05]\n",
      " [ 0.00000000e+00  0.00000000e+00]\n",
      " [-2.06287168e-05 -1.38339106e-04]\n",
      " [-2.48457654e-05 -1.66619226e-04]\n",
      " [-5.92207143e-05 -3.97142547e-04]\n",
      " [-5.97839171e-05 -4.00919467e-04]\n",
      " [-5.32406739e-05 -3.57039535e-04]\n",
      " [-2.87909588e-05 -1.93076266e-04]\n",
      " [-6.40607250e-05 -4.29600303e-04]\n",
      " [-4.61603631e-05 -3.09557945e-04]\n",
      " [-3.82332400e-05 -2.56397529e-04]\n",
      " [-5.84147456e-05 -3.91737587e-04]\n",
      " [-6.69658330e-05 -4.49082378e-04]\n",
      " [-5.76543353e-05 -3.86638159e-04]\n",
      " [-6.49796784e-05 -4.35762951e-04]\n",
      " [-4.94249689e-05 -3.31450865e-04]\n",
      " [-7.16457143e-05 -4.80466348e-04]\n",
      " [-7.29827589e-05 -4.89432772e-04]\n",
      " [-3.63588515e-05 -2.43827628e-04]\n",
      " [-7.10109962e-05 -4.76209854e-04]\n",
      " [-6.72249225e-05 -4.50819905e-04]\n",
      " [-5.68734358e-05 -3.81401362e-04]\n",
      " [-3.25402871e-05 -2.18219793e-04]\n",
      " [-3.97949298e-05 -2.66870455e-04]\n",
      " [-6.83057297e-05 -4.58067952e-04]\n",
      " [-3.60830672e-05 -2.41978167e-04]\n",
      " [-7.76278539e-05 -5.20583417e-04]\n",
      " [-5.68285795e-05 -3.81100544e-04]\n",
      " [-5.19684108e-05 -3.48507572e-04]\n",
      " [-2.21694936e-05 -1.48671767e-04]\n",
      " [-6.16844554e-05 -4.13664704e-04]\n",
      " [-9.49034893e-06 -6.36436307e-05]\n",
      " [-1.78717251e-04 -1.19850331e-03]\n",
      " [ 0.00000000e+00  0.00000000e+00]\n",
      " [-1.43718164e-04 -9.63794475e-04]\n",
      " [-1.38552510e-04 -9.29152768e-04]\n",
      " [-6.51950759e-05 -4.37207462e-04]\n",
      " [-1.88496953e-04 -1.26408739e-03]\n",
      " [-1.71304651e-04 -1.14879338e-03]\n",
      " [-2.00203038e-04 -1.34258997e-03]\n",
      " [-1.99519272e-04 -1.33800460e-03]\n",
      " [-1.14345690e-04 -7.66818470e-04]\n",
      " [-1.66985817e-04 -1.11983065e-03]\n",
      " [ 0.00000000e+00  0.00000000e+00]\n",
      " [-2.08415031e-06 -1.39766071e-05]\n",
      " [-3.12441830e-06 -2.09527934e-05]\n",
      " [-5.19530977e-06 -3.48404865e-05]\n",
      " [-6.42000077e-06 -4.30534383e-05]\n",
      " [-9.83438986e-06 -6.59508223e-05]\n",
      " [-1.06406678e-05 -7.13578338e-05]\n",
      " [-1.39607519e-05 -9.36227880e-05]\n",
      " [-9.81849371e-06 -6.58442150e-05]\n",
      " [-1.24579083e-05 -8.35445026e-05]\n",
      " [-1.57731802e-06 -1.05777190e-05]\n",
      " [-6.41321367e-06 -4.30079199e-05]\n",
      " [ 0.00000000e+00  0.00000000e+00]\n",
      " [-1.26732239e-05 -8.49884455e-05]\n",
      " [-1.73397093e-05 -1.16282557e-04]\n",
      " [-7.44602448e-06 -4.99341004e-05]\n",
      " [ 0.00000000e+00  0.00000000e+00]\n",
      " [-4.07107518e-06 -2.73012083e-05]\n",
      " [-1.70398052e-05 -1.14271352e-04]\n",
      " [-4.39198629e-06 -2.94532838e-05]\n",
      " [-4.39302994e-07 -2.94602842e-06]\n",
      " [-5.85771068e-06 -3.92826405e-05]\n",
      " [-7.00927512e-06 -4.70051964e-05]\n",
      " [-1.78044284e-05 -1.19399025e-04]\n",
      " [ 0.00000000e+00  0.00000000e+00]\n",
      " [-1.92438292e-05 -1.29051856e-04]\n",
      " [-2.21542323e-05 -1.48569437e-04]\n",
      " [-2.46410218e-05 -1.65246194e-04]\n",
      " [-2.10744947e-05 -1.41328550e-04]\n",
      " [-2.60936577e-05 -1.74987785e-04]\n",
      " [-1.80659645e-05 -1.21152931e-04]\n",
      " [-2.87460025e-05 -1.92774780e-04]\n",
      " [-3.04060413e-05 -2.03907242e-04]\n",
      " [-3.10053474e-05 -2.07926263e-04]\n",
      " [-3.11907461e-05 -2.09169593e-04]\n",
      " [-2.57601478e-05 -1.72751214e-04]\n",
      " [-1.06030147e-05 -7.11053217e-05]\n",
      " [-3.14878744e-05 -2.11162158e-04]\n",
      " [-2.38089178e-05 -1.59665986e-04]\n",
      " [-1.58182738e-05 -1.06079598e-04]\n",
      " [-3.48206122e-05 -2.33511964e-04]\n",
      " [-2.96009039e-05 -1.98507871e-04]\n",
      " [-2.13488056e-05 -1.43168130e-04]\n",
      " [-2.10682010e-05 -1.41286349e-04]\n",
      " [-1.72966720e-05 -1.15993942e-04]\n",
      " [-3.94661693e-05 -2.64665723e-04]\n",
      " [-4.36620467e-05 -2.92803888e-04]\n",
      " [-5.01638424e-05 -3.36405850e-04]\n",
      " [-1.11323625e-05 -7.46552032e-05]\n",
      " [-2.29439556e-05 -1.53865432e-04]\n",
      " [-5.54812759e-05 -3.72065319e-04]\n",
      " [-1.20062150e-05 -8.05153832e-05]\n",
      " [-5.88420626e-05 -3.94603238e-04]\n",
      " [-4.74518929e-05 -3.18219129e-04]\n",
      " [-9.77651580e-05 -6.55627053e-04]\n",
      " [-1.04906750e-04 -7.03519559e-04]\n",
      " [-6.04197412e-05 -4.05183353e-04]\n",
      " [-3.68970941e-05 -2.47437158e-04]\n",
      " [-3.76851531e-05 -2.52721977e-04]\n",
      " [-1.22966827e-04 -8.24632996e-04]\n",
      " [-8.21709255e-05 -5.51049889e-04]\n",
      " [-1.16622621e-04 -7.82087853e-04]\n",
      " [-1.21269266e-04 -8.13248917e-04]\n",
      " [-1.31497567e-04 -8.81841348e-04]\n",
      " [-9.06664645e-05 -6.08022208e-04]\n",
      " [-1.27983134e-04 -8.58273066e-04]\n",
      " [-1.13148497e-04 -7.58789945e-04]\n",
      " [-1.23375125e-04 -8.27371143e-04]\n",
      " [-1.31193141e-04 -8.79799831e-04]\n",
      " [-1.09573222e-04 -7.34813628e-04]\n",
      " [-8.08277036e-05 -5.42042078e-04]\n",
      " [-1.27429914e-04 -8.54563084e-04]\n",
      " [-2.13927888e-05 -1.43463083e-04]\n",
      " [-4.00833524e-05 -2.68804666e-04]\n",
      " [-1.01748810e-04 -6.82341983e-04]\n",
      " [-7.05483981e-05 -4.73107561e-04]\n",
      " [ 0.00000000e+00  0.00000000e+00]\n",
      " [-1.70042513e-05 -1.14032926e-04]\n",
      " [-1.39487151e-04 -9.35420685e-04]\n",
      " [-6.82499594e-05 -4.57693939e-04]\n",
      " [-6.37316998e-06 -4.27393825e-05]\n",
      " [-5.42934322e-05 -3.64099484e-04]\n",
      " [ 0.00000000e+00  0.00000000e+00]\n",
      " [-7.65145378e-05 -5.13117353e-04]\n",
      " [-5.23094823e-05 -3.50794842e-04]\n",
      " [-6.79772784e-05 -4.55865287e-04]\n",
      " [-1.84743658e-05 -1.23891732e-04]\n",
      " [-8.51691584e-05 -5.71156444e-04]\n",
      " [-8.33730228e-05 -5.59111300e-04]\n",
      " [-8.70910444e-05 -5.84044901e-04]\n",
      " [-6.56341435e-05 -4.40151925e-04]\n",
      " [-7.58485403e-05 -5.08651079e-04]\n",
      " [-4.80522831e-05 -3.22245440e-04]\n",
      " [-7.29349995e-05 -4.89112514e-04]\n",
      " [-9.23483676e-05 -6.19301281e-04]\n",
      " [-7.33668712e-05 -4.92008636e-04]\n",
      " [-9.21826722e-05 -6.18190097e-04]\n",
      " [-8.03384683e-05 -5.38761204e-04]\n",
      " [-9.50284521e-05 -6.37274352e-04]\n",
      " [-7.48187813e-05 -5.01745380e-04]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "np.random.seed(0)\n",
    "import nnfs\n",
    "from nnfs.datasets import spiral_data\n",
    "\n",
    "nnfs.init()\n",
    "\n",
    "class LayerDense:\n",
    "    def __init__(self, n_inputs, n_neurons):\n",
    "        self.weights = 0.10 * np.random.randn(n_inputs, n_neurons)\n",
    "        self.biases = np.zeros((1, n_neurons))\n",
    "    def forward(self, inputs):\n",
    "        self.output = np.dot(inputs, self.weights) + self.biases\n",
    "\n",
    "class ActivationReLU:  \n",
    "    def forward(self, inputs):\n",
    "        self.output = np.maximum(0, inputs)\n",
    "        \n",
    "def create_network(layer_sizes):\n",
    "    network = []\n",
    "    for i in range(1, len(layer_sizes)):\n",
    "        network.append(LayerDense(layer_sizes[i-1], layer_sizes[i]))\n",
    "        if i < len(layer_sizes) - 1:\n",
    "            network.append(ActivationReLU())\n",
    "    return network\n",
    "\n",
    "def forward(network, X):\n",
    "    for layer in network:\n",
    "        layer.forward(X)\n",
    "        X = layer.output\n",
    "    return X\n",
    "\n",
    "num_layers = int(input(\"Enter the number of layers: \"))\n",
    "layer_neurons = []\n",
    "for i in range(num_layers):\n",
    "    neurons = int(input(f\"Enter the number of neurons in layer {i+1}: \"))\n",
    "    layer_neurons.append(neurons)\n",
    "\n",
    "X, y = spiral_data(samples=100, classes=3)        \n",
    "\n",
    "network = create_network(layer_neurons)\n",
    "output = forward(network, X)\n",
    "\n",
    "print(output)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "782c2ed1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter the number of layers: 4\n",
      "Enter the number of neurons in layer 1: 2\n",
      "Enter the number of neurons in layer 2: 3\n",
      "Enter the number of neurons in layer 3: 3\n",
      "Enter the number of neurons in layer 4: 2\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "index 2 is out of bounds for axis 1 with size 2",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[14], line 55\u001b[0m\n\u001b[1;32m     52\u001b[0m output \u001b[38;5;241m=\u001b[39m forward(network, X)\n\u001b[1;32m     54\u001b[0m loss_function \u001b[38;5;241m=\u001b[39m LossMultiClassSVM()\n\u001b[0;32m---> 55\u001b[0m loss \u001b[38;5;241m=\u001b[39m loss_function\u001b[38;5;241m.\u001b[39mforward(output, y)\n\u001b[1;32m     57\u001b[0m \u001b[38;5;28mprint\u001b[39m(loss)\n",
      "Cell \u001b[0;32mIn[14], line 23\u001b[0m, in \u001b[0;36mLossMultiClassSVM.forward\u001b[0;34m(self, scores, y)\u001b[0m\n\u001b[1;32m     21\u001b[0m num_classes \u001b[38;5;241m=\u001b[39m scores\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m     22\u001b[0m num_examples \u001b[38;5;241m=\u001b[39m scores\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m---> 23\u001b[0m correct_class_scores \u001b[38;5;241m=\u001b[39m scores[np\u001b[38;5;241m.\u001b[39marange(num_examples), y]\n\u001b[1;32m     24\u001b[0m margins \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mmaximum(\u001b[38;5;241m0\u001b[39m, scores \u001b[38;5;241m-\u001b[39m correct_class_scores[:, np\u001b[38;5;241m.\u001b[39mnewaxis] \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1.0\u001b[39m)\n\u001b[1;32m     25\u001b[0m margins[np\u001b[38;5;241m.\u001b[39marange(num_examples), y] \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n",
      "\u001b[0;31mIndexError\u001b[0m: index 2 is out of bounds for axis 1 with size 2"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "np.random.seed(0)\n",
    "import nnfs\n",
    "from nnfs.datasets import spiral_data\n",
    "\n",
    "nnfs.init()\n",
    "\n",
    "class LayerDense:\n",
    "    def __init__(self, n_inputs, n_neurons):\n",
    "        self.weights = 0.10 * np.random.randn(n_inputs, n_neurons)\n",
    "        self.biases = np.zeros((1, n_neurons))\n",
    "    def forward(self, inputs):\n",
    "        self.output = np.dot(inputs, self.weights) + self.biases\n",
    "\n",
    "class ActivationReLU:  \n",
    "    def forward(self, inputs):\n",
    "        self.output = np.maximum(0, inputs)\n",
    "\n",
    "class LossMultiClassSVM:\n",
    "    def forward(self, scores, y):\n",
    "        num_classes = scores.shape[1]\n",
    "        num_examples = scores.shape[0]\n",
    "        correct_class_scores = scores[np.arange(num_examples), y]\n",
    "        margins = np.maximum(0, scores - correct_class_scores[:, np.newaxis] + 1.0)\n",
    "        margins[np.arange(num_examples), y] = 0\n",
    "        loss = np.sum(margins) / num_examples\n",
    "        return loss\n",
    "\n",
    "def create_network(layer_sizes):\n",
    "    network = []\n",
    "    for i in range(1, len(layer_sizes)):\n",
    "        network.append(LayerDense(layer_sizes[i-1], layer_sizes[i]))\n",
    "        if i < len(layer_sizes) - 1:\n",
    "            network.append(ActivationReLU())\n",
    "    return network\n",
    "\n",
    "def forward(network, X):\n",
    "    for layer in network:\n",
    "        layer.forward(X)\n",
    "        X = layer.output\n",
    "    return X\n",
    "\n",
    "num_layers = int(input(\"Enter the number of layers: \"))\n",
    "layer_neurons = []\n",
    "for i in range(num_layers):\n",
    "    neurons = int(input(f\"Enter the number of neurons in layer {i+1}: \"))\n",
    "    layer_neurons.append(neurons)\n",
    "\n",
    "X, y = spiral_data(samples=100, classes=3)        \n",
    "\n",
    "network = create_network(layer_neurons)\n",
    "output = forward(network, X)\n",
    "\n",
    "loss_function = LossMultiClassSVM()\n",
    "loss = loss_function.forward(output, y)\n",
    "\n",
    "print(loss)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "814f0c94",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter the number of layers: 4\n",
      "Enter the number of neurons in layer 1: 2\n",
      "Enter the number of neurons in layer 2: 3\n",
      "Enter the number of neurons in layer 3: 3\n",
      "Enter the number of neurons in layer 4: 2\n",
      "1.99998779296875\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "np.random.seed(0)\n",
    "import nnfs\n",
    "from nnfs.datasets import spiral_data\n",
    "\n",
    "nnfs.init()\n",
    "\n",
    "class LayerDense:\n",
    "    def __init__(self, n_inputs, n_neurons):\n",
    "        self.weights = 0.10 * np.random.randn(n_inputs, n_neurons)\n",
    "        self.biases = np.zeros((1, n_neurons))\n",
    "    def forward(self, inputs):\n",
    "        self.output = np.dot(inputs, self.weights) + self.biases\n",
    "\n",
    "class ActivationReLU:  \n",
    "    def forward(self, inputs):\n",
    "        self.output = np.maximum(0, inputs)\n",
    "\n",
    "class LossMultiClassSVM:\n",
    "    def forward(self, scores, y):\n",
    "        num_classes = scores.shape[1]\n",
    "        num_examples = scores.shape[0]\n",
    "        correct_class_scores = scores[np.arange(num_examples), y]\n",
    "        margins = np.maximum(0, scores - correct_class_scores[:, np.newaxis] + 1.0)\n",
    "        margins[np.arange(num_examples), y] = 0\n",
    "        loss = np.sum(margins) / num_examples\n",
    "        return loss\n",
    "\n",
    "def create_network(layer_sizes):\n",
    "    network = []\n",
    "    for i in range(1, len(layer_sizes)):\n",
    "        network.append(LayerDense(layer_sizes[i-1], layer_sizes[i]))\n",
    "        if i < len(layer_sizes) - 1:\n",
    "            network.append(ActivationReLU())\n",
    "    return network\n",
    "\n",
    "def forward(network, X):\n",
    "    for layer in network:\n",
    "        layer.forward(X)\n",
    "        X = layer.output\n",
    "    return X\n",
    "\n",
    "num_layers = int(input(\"Enter the number of layers: \"))\n",
    "layer_neurons = []\n",
    "for i in range(num_layers):\n",
    "    neurons = int(input(f\"Enter the number of neurons in layer {i+1}: \"))\n",
    "    layer_neurons.append(neurons)\n",
    "\n",
    "X, y = spiral_data(samples=100, classes=3)        \n",
    "\n",
    "# Adjusting the last layer neurons to match the number of classes\n",
    "layer_neurons[-1] = len(np.unique(y))\n",
    "\n",
    "network = create_network(layer_neurons)\n",
    "output = forward(network, X)\n",
    "\n",
    "loss_function = LossMultiClassSVM()\n",
    "loss = loss_function.forward(output, y)\n",
    "\n",
    "print(loss)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3b84feee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter the number of layers: 4\n",
      "Enter the number of neurons in layer 1: 4\n",
      "Enter the number of neurons in layer 2: 5\n",
      "Enter the number of neurons in layer 3: 5\n",
      "Train Loss: 2.0015716552734375\n",
      "Test Loss: 2.0030540466308593\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "np.random.seed(0)\n",
    "import nnfs\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "nnfs.init()\n",
    "\n",
    "class LayerDense:\n",
    "    def __init__(self, n_inputs, n_neurons):\n",
    "        self.weights = 0.10 * np.random.randn(n_inputs, n_neurons)\n",
    "        self.biases = np.zeros((1, n_neurons))\n",
    "    def forward(self, inputs):\n",
    "        self.output = np.dot(inputs, self.weights) + self.biases\n",
    "\n",
    "class ActivationReLU:  \n",
    "    def forward(self, inputs):\n",
    "        self.output = np.maximum(0, inputs)\n",
    "\n",
    "class LossMultiClassSVM:\n",
    "    def forward(self, scores, y):\n",
    "        num_classes = scores.shape[1]\n",
    "        num_examples = scores.shape[0]\n",
    "        correct_class_scores = scores[np.arange(num_examples), y]\n",
    "        margins = np.maximum(0, scores - correct_class_scores[:, np.newaxis] + 1.0)\n",
    "        margins[np.arange(num_examples), y] = 0\n",
    "        loss = np.sum(margins) / num_examples\n",
    "        return loss\n",
    "\n",
    "def create_network(layer_sizes):\n",
    "    network = []\n",
    "    for i in range(1, len(layer_sizes)):\n",
    "        network.append(LayerDense(layer_sizes[i-1], layer_sizes[i]))\n",
    "        if i < len(layer_sizes) - 1:\n",
    "            network.append(ActivationReLU())\n",
    "    return network\n",
    "\n",
    "def forward(network, X):\n",
    "    for layer in network:\n",
    "        layer.forward(X)\n",
    "        X = layer.output\n",
    "    return X\n",
    "\n",
    "# Load Iris dataset\n",
    "iris = load_iris()\n",
    "X, y = iris.data, iris.target\n",
    "\n",
    "# Split dataset into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "num_features = X_train.shape[1]\n",
    "num_classes = len(np.unique(y_train))\n",
    "\n",
    "num_layers = int(input(\"Enter the number of layers: \"))\n",
    "layer_neurons = [num_features]  # Input layer\n",
    "\n",
    "for i in range(num_layers - 1):\n",
    "    neurons = int(input(f\"Enter the number of neurons in layer {i+1}: \"))\n",
    "    layer_neurons.append(neurons)\n",
    "\n",
    "layer_neurons.append(num_classes)  # Output layer\n",
    "\n",
    "network = create_network(layer_neurons)\n",
    "output_train = forward(network, X_train)\n",
    "output_test = forward(network, X_test)\n",
    "\n",
    "loss_function = LossMultiClassSVM()\n",
    "train_loss = loss_function.forward(output_train, y_train)\n",
    "test_loss = loss_function.forward(output_test, y_test)\n",
    "\n",
    "print(\"Train Loss:\", train_loss)\n",
    "print(\"Test Loss:\", test_loss)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "68a5b448",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter the number of layers: 4\n",
      "Enter the number of neurons in layer 1: 4\n",
      "Enter the number of neurons in layer 2: 5\n",
      "Enter the number of neurons in layer 3: 5\n",
      "Train Loss: 2.0015716552734375\n",
      "Test Loss: 2.0030540466308593\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "np.random.seed(0)\n",
    "import nnfs\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "nnfs.init()\n",
    "\n",
    "class LayerDense:\n",
    "    def __init__(self, n_inputs, n_neurons):\n",
    "        self.weights = 0.10 * np.random.randn(n_inputs, n_neurons)\n",
    "        self.biases = np.zeros((1, n_neurons))\n",
    "    def forward(self, inputs):\n",
    "        self.output = np.dot(inputs, self.weights) + self.biases\n",
    "\n",
    "class ActivationReLU:  \n",
    "    def forward(self, inputs):\n",
    "        self.output = np.maximum(0, inputs)\n",
    "\n",
    "class LossMultiClassSVM:\n",
    "    def forward(self, scores, y):\n",
    "        num_classes = scores.shape[1]\n",
    "        num_examples = scores.shape[0]\n",
    "        correct_class_scores = scores[np.arange(num_examples), y]\n",
    "        margins = np.maximum(0, scores - correct_class_scores[:, np.newaxis] + 1.0)\n",
    "        margins[np.arange(num_examples), y] = 0\n",
    "        loss = np.sum(margins) / num_examples\n",
    "        return loss\n",
    "\n",
    "class NeuralNetwork:\n",
    "    def __init__(self, layer_sizes):\n",
    "        self.layers = self.create_network(layer_sizes)\n",
    "        \n",
    "    def create_network(self, layer_sizes):\n",
    "        network = []\n",
    "        for i in range(1, len(layer_sizes)):\n",
    "            network.append(LayerDense(layer_sizes[i-1], layer_sizes[i]))\n",
    "            if i < len(layer_sizes) - 1:\n",
    "                network.append(ActivationReLU())\n",
    "        return network\n",
    "    \n",
    "    def forward(self, X):\n",
    "        for layer in self.layers:\n",
    "            layer.forward(X)\n",
    "            X = layer.output\n",
    "        return X\n",
    "\n",
    "def load_iris_dataset():\n",
    "    iris = load_iris()\n",
    "    X, y = iris.data, iris.target\n",
    "    return X, y\n",
    "\n",
    "def split_dataset(X, y, test_size=0.2, random_state=42):\n",
    "    return train_test_split(X, y, test_size=test_size, random_state=random_state)\n",
    "\n",
    "def main():\n",
    "    X, y = load_iris_dataset()\n",
    "    X_train, X_test, y_train, y_test = split_dataset(X, y)\n",
    "    \n",
    "    num_features = X_train.shape[1]\n",
    "    num_classes = len(np.unique(y_train))\n",
    "\n",
    "    num_layers = int(input(\"Enter the number of layers: \"))\n",
    "    layer_neurons = [num_features]  # Input layer\n",
    "\n",
    "    for i in range(num_layers - 1):\n",
    "        neurons = int(input(f\"Enter the number of neurons in layer {i+1}: \"))\n",
    "        layer_neurons.append(neurons)\n",
    "\n",
    "    layer_neurons.append(num_classes)  # Output layer\n",
    "\n",
    "    neural_net = NeuralNetwork(layer_neurons)\n",
    "    output_train = neural_net.forward(X_train)\n",
    "    output_test = neural_net.forward(X_test)\n",
    "\n",
    "    loss_function = LossMultiClassSVM()\n",
    "    train_loss = loss_function.forward(output_train, y_train)\n",
    "    test_loss = loss_function.forward(output_test, y_test)\n",
    "\n",
    "    print(\"Train Loss:\", train_loss)\n",
    "    print(\"Test Loss:\", test_loss)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "414abe61",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter the number of layers: 3\n",
      "Enter the number of neurons in layer 1: 8\n",
      "Enter the number of neurons in layer 2: 8\n",
      "Enter the number of epochs: 100\n",
      "Enter the learning rate: 0.001\n",
      "Epoch 1/100 - Train Loss: 1.9994 - Train Accuracy: 0.3250 - Test Loss: 1.9854 - Test Accuracy: 0.3667\n",
      "Epoch 2/100 - Train Loss: 1.9994 - Train Accuracy: 0.3250 - Test Loss: 1.9854 - Test Accuracy: 0.3667\n",
      "Epoch 3/100 - Train Loss: 1.9994 - Train Accuracy: 0.3250 - Test Loss: 1.9854 - Test Accuracy: 0.3667\n",
      "Epoch 4/100 - Train Loss: 1.9994 - Train Accuracy: 0.3250 - Test Loss: 1.9854 - Test Accuracy: 0.3667\n",
      "Epoch 5/100 - Train Loss: 1.9994 - Train Accuracy: 0.3250 - Test Loss: 1.9854 - Test Accuracy: 0.3667\n",
      "Epoch 6/100 - Train Loss: 1.9994 - Train Accuracy: 0.3250 - Test Loss: 1.9854 - Test Accuracy: 0.3667\n",
      "Epoch 7/100 - Train Loss: 1.9994 - Train Accuracy: 0.3250 - Test Loss: 1.9854 - Test Accuracy: 0.3667\n",
      "Epoch 8/100 - Train Loss: 1.9994 - Train Accuracy: 0.3250 - Test Loss: 1.9854 - Test Accuracy: 0.3667\n",
      "Epoch 9/100 - Train Loss: 1.9994 - Train Accuracy: 0.3250 - Test Loss: 1.9854 - Test Accuracy: 0.3667\n",
      "Epoch 10/100 - Train Loss: 1.9994 - Train Accuracy: 0.3250 - Test Loss: 1.9854 - Test Accuracy: 0.3667\n",
      "Epoch 11/100 - Train Loss: 1.9994 - Train Accuracy: 0.3250 - Test Loss: 1.9854 - Test Accuracy: 0.3667\n",
      "Epoch 12/100 - Train Loss: 1.9994 - Train Accuracy: 0.3250 - Test Loss: 1.9854 - Test Accuracy: 0.3667\n",
      "Epoch 13/100 - Train Loss: 1.9994 - Train Accuracy: 0.3250 - Test Loss: 1.9854 - Test Accuracy: 0.3667\n",
      "Epoch 14/100 - Train Loss: 1.9994 - Train Accuracy: 0.3250 - Test Loss: 1.9854 - Test Accuracy: 0.3667\n",
      "Epoch 15/100 - Train Loss: 1.9994 - Train Accuracy: 0.3250 - Test Loss: 1.9854 - Test Accuracy: 0.3667\n",
      "Epoch 16/100 - Train Loss: 1.9994 - Train Accuracy: 0.3250 - Test Loss: 1.9854 - Test Accuracy: 0.3667\n",
      "Epoch 17/100 - Train Loss: 1.9994 - Train Accuracy: 0.3250 - Test Loss: 1.9854 - Test Accuracy: 0.3667\n",
      "Epoch 18/100 - Train Loss: 1.9994 - Train Accuracy: 0.3250 - Test Loss: 1.9854 - Test Accuracy: 0.3667\n",
      "Epoch 19/100 - Train Loss: 1.9994 - Train Accuracy: 0.3250 - Test Loss: 1.9854 - Test Accuracy: 0.3667\n",
      "Epoch 20/100 - Train Loss: 1.9994 - Train Accuracy: 0.3250 - Test Loss: 1.9854 - Test Accuracy: 0.3667\n",
      "Epoch 21/100 - Train Loss: 1.9994 - Train Accuracy: 0.3250 - Test Loss: 1.9854 - Test Accuracy: 0.3667\n",
      "Epoch 22/100 - Train Loss: 1.9994 - Train Accuracy: 0.3250 - Test Loss: 1.9854 - Test Accuracy: 0.3667\n",
      "Epoch 23/100 - Train Loss: 1.9994 - Train Accuracy: 0.3250 - Test Loss: 1.9854 - Test Accuracy: 0.3667\n",
      "Epoch 24/100 - Train Loss: 1.9994 - Train Accuracy: 0.3250 - Test Loss: 1.9854 - Test Accuracy: 0.3667\n",
      "Epoch 25/100 - Train Loss: 1.9994 - Train Accuracy: 0.3250 - Test Loss: 1.9854 - Test Accuracy: 0.3667\n",
      "Epoch 26/100 - Train Loss: 1.9994 - Train Accuracy: 0.3250 - Test Loss: 1.9854 - Test Accuracy: 0.3667\n",
      "Epoch 27/100 - Train Loss: 1.9994 - Train Accuracy: 0.3250 - Test Loss: 1.9854 - Test Accuracy: 0.3667\n",
      "Epoch 28/100 - Train Loss: 1.9994 - Train Accuracy: 0.3250 - Test Loss: 1.9854 - Test Accuracy: 0.3667\n",
      "Epoch 29/100 - Train Loss: 1.9994 - Train Accuracy: 0.3250 - Test Loss: 1.9854 - Test Accuracy: 0.3667\n",
      "Epoch 30/100 - Train Loss: 1.9994 - Train Accuracy: 0.3250 - Test Loss: 1.9854 - Test Accuracy: 0.3667\n",
      "Epoch 31/100 - Train Loss: 1.9994 - Train Accuracy: 0.3250 - Test Loss: 1.9854 - Test Accuracy: 0.3667\n",
      "Epoch 32/100 - Train Loss: 1.9994 - Train Accuracy: 0.3250 - Test Loss: 1.9854 - Test Accuracy: 0.3667\n",
      "Epoch 33/100 - Train Loss: 1.9994 - Train Accuracy: 0.3250 - Test Loss: 1.9854 - Test Accuracy: 0.3667\n",
      "Epoch 34/100 - Train Loss: 1.9994 - Train Accuracy: 0.3250 - Test Loss: 1.9854 - Test Accuracy: 0.3667\n",
      "Epoch 35/100 - Train Loss: 1.9994 - Train Accuracy: 0.3250 - Test Loss: 1.9854 - Test Accuracy: 0.3667\n",
      "Epoch 36/100 - Train Loss: 1.9994 - Train Accuracy: 0.3250 - Test Loss: 1.9854 - Test Accuracy: 0.3667\n",
      "Epoch 37/100 - Train Loss: 1.9994 - Train Accuracy: 0.3250 - Test Loss: 1.9854 - Test Accuracy: 0.3667\n",
      "Epoch 38/100 - Train Loss: 1.9994 - Train Accuracy: 0.3250 - Test Loss: 1.9854 - Test Accuracy: 0.3667\n",
      "Epoch 39/100 - Train Loss: 1.9994 - Train Accuracy: 0.3250 - Test Loss: 1.9854 - Test Accuracy: 0.3667\n",
      "Epoch 40/100 - Train Loss: 1.9994 - Train Accuracy: 0.3250 - Test Loss: 1.9854 - Test Accuracy: 0.3667\n",
      "Epoch 41/100 - Train Loss: 1.9994 - Train Accuracy: 0.3250 - Test Loss: 1.9854 - Test Accuracy: 0.3667\n",
      "Epoch 42/100 - Train Loss: 1.9994 - Train Accuracy: 0.3250 - Test Loss: 1.9854 - Test Accuracy: 0.3667\n",
      "Epoch 43/100 - Train Loss: 1.9994 - Train Accuracy: 0.3250 - Test Loss: 1.9854 - Test Accuracy: 0.3667\n",
      "Epoch 44/100 - Train Loss: 1.9994 - Train Accuracy: 0.3250 - Test Loss: 1.9854 - Test Accuracy: 0.3667\n",
      "Epoch 45/100 - Train Loss: 1.9994 - Train Accuracy: 0.3250 - Test Loss: 1.9854 - Test Accuracy: 0.3667\n",
      "Epoch 46/100 - Train Loss: 1.9994 - Train Accuracy: 0.3250 - Test Loss: 1.9854 - Test Accuracy: 0.3667\n",
      "Epoch 47/100 - Train Loss: 1.9994 - Train Accuracy: 0.3250 - Test Loss: 1.9854 - Test Accuracy: 0.3667\n",
      "Epoch 48/100 - Train Loss: 1.9994 - Train Accuracy: 0.3250 - Test Loss: 1.9854 - Test Accuracy: 0.3667\n",
      "Epoch 49/100 - Train Loss: 1.9994 - Train Accuracy: 0.3250 - Test Loss: 1.9854 - Test Accuracy: 0.3667\n",
      "Epoch 50/100 - Train Loss: 1.9994 - Train Accuracy: 0.3250 - Test Loss: 1.9854 - Test Accuracy: 0.3667\n",
      "Epoch 51/100 - Train Loss: 1.9994 - Train Accuracy: 0.3250 - Test Loss: 1.9854 - Test Accuracy: 0.3667\n",
      "Epoch 52/100 - Train Loss: 1.9994 - Train Accuracy: 0.3250 - Test Loss: 1.9854 - Test Accuracy: 0.3667\n",
      "Epoch 53/100 - Train Loss: 1.9994 - Train Accuracy: 0.3250 - Test Loss: 1.9854 - Test Accuracy: 0.3667\n",
      "Epoch 54/100 - Train Loss: 1.9994 - Train Accuracy: 0.3250 - Test Loss: 1.9854 - Test Accuracy: 0.3667\n",
      "Epoch 55/100 - Train Loss: 1.9994 - Train Accuracy: 0.3250 - Test Loss: 1.9854 - Test Accuracy: 0.3667\n",
      "Epoch 56/100 - Train Loss: 1.9994 - Train Accuracy: 0.3250 - Test Loss: 1.9854 - Test Accuracy: 0.3667\n",
      "Epoch 57/100 - Train Loss: 1.9994 - Train Accuracy: 0.3250 - Test Loss: 1.9854 - Test Accuracy: 0.3667\n",
      "Epoch 58/100 - Train Loss: 1.9994 - Train Accuracy: 0.3250 - Test Loss: 1.9854 - Test Accuracy: 0.3667\n",
      "Epoch 59/100 - Train Loss: 1.9994 - Train Accuracy: 0.3250 - Test Loss: 1.9854 - Test Accuracy: 0.3667\n",
      "Epoch 60/100 - Train Loss: 1.9994 - Train Accuracy: 0.3250 - Test Loss: 1.9854 - Test Accuracy: 0.3667\n",
      "Epoch 61/100 - Train Loss: 1.9994 - Train Accuracy: 0.3250 - Test Loss: 1.9854 - Test Accuracy: 0.3667\n",
      "Epoch 62/100 - Train Loss: 1.9994 - Train Accuracy: 0.3250 - Test Loss: 1.9854 - Test Accuracy: 0.3667\n",
      "Epoch 63/100 - Train Loss: 1.9994 - Train Accuracy: 0.3250 - Test Loss: 1.9854 - Test Accuracy: 0.3667\n",
      "Epoch 64/100 - Train Loss: 1.9994 - Train Accuracy: 0.3250 - Test Loss: 1.9854 - Test Accuracy: 0.3667\n",
      "Epoch 65/100 - Train Loss: 1.9994 - Train Accuracy: 0.3250 - Test Loss: 1.9854 - Test Accuracy: 0.3667\n",
      "Epoch 66/100 - Train Loss: 1.9994 - Train Accuracy: 0.3250 - Test Loss: 1.9854 - Test Accuracy: 0.3667\n",
      "Epoch 67/100 - Train Loss: 1.9994 - Train Accuracy: 0.3250 - Test Loss: 1.9854 - Test Accuracy: 0.3667\n",
      "Epoch 68/100 - Train Loss: 1.9994 - Train Accuracy: 0.3250 - Test Loss: 1.9854 - Test Accuracy: 0.3667\n",
      "Epoch 69/100 - Train Loss: 1.9994 - Train Accuracy: 0.3250 - Test Loss: 1.9854 - Test Accuracy: 0.3667\n",
      "Epoch 70/100 - Train Loss: 1.9994 - Train Accuracy: 0.3250 - Test Loss: 1.9854 - Test Accuracy: 0.3667\n",
      "Epoch 71/100 - Train Loss: 1.9994 - Train Accuracy: 0.3250 - Test Loss: 1.9854 - Test Accuracy: 0.3667\n",
      "Epoch 72/100 - Train Loss: 1.9994 - Train Accuracy: 0.3250 - Test Loss: 1.9854 - Test Accuracy: 0.3667\n",
      "Epoch 73/100 - Train Loss: 1.9994 - Train Accuracy: 0.3250 - Test Loss: 1.9854 - Test Accuracy: 0.3667\n",
      "Epoch 74/100 - Train Loss: 1.9994 - Train Accuracy: 0.3250 - Test Loss: 1.9854 - Test Accuracy: 0.3667\n",
      "Epoch 75/100 - Train Loss: 1.9994 - Train Accuracy: 0.3250 - Test Loss: 1.9854 - Test Accuracy: 0.3667\n",
      "Epoch 76/100 - Train Loss: 1.9994 - Train Accuracy: 0.3250 - Test Loss: 1.9854 - Test Accuracy: 0.3667\n",
      "Epoch 77/100 - Train Loss: 1.9994 - Train Accuracy: 0.3250 - Test Loss: 1.9854 - Test Accuracy: 0.3667\n",
      "Epoch 78/100 - Train Loss: 1.9994 - Train Accuracy: 0.3250 - Test Loss: 1.9854 - Test Accuracy: 0.3667\n",
      "Epoch 79/100 - Train Loss: 1.9994 - Train Accuracy: 0.3250 - Test Loss: 1.9854 - Test Accuracy: 0.3667\n",
      "Epoch 80/100 - Train Loss: 1.9994 - Train Accuracy: 0.3250 - Test Loss: 1.9854 - Test Accuracy: 0.3667\n",
      "Epoch 81/100 - Train Loss: 1.9994 - Train Accuracy: 0.3250 - Test Loss: 1.9854 - Test Accuracy: 0.3667\n",
      "Epoch 82/100 - Train Loss: 1.9994 - Train Accuracy: 0.3250 - Test Loss: 1.9854 - Test Accuracy: 0.3667\n",
      "Epoch 83/100 - Train Loss: 1.9994 - Train Accuracy: 0.3250 - Test Loss: 1.9854 - Test Accuracy: 0.3667\n",
      "Epoch 84/100 - Train Loss: 1.9994 - Train Accuracy: 0.3250 - Test Loss: 1.9854 - Test Accuracy: 0.3667\n",
      "Epoch 85/100 - Train Loss: 1.9994 - Train Accuracy: 0.3250 - Test Loss: 1.9854 - Test Accuracy: 0.3667\n",
      "Epoch 86/100 - Train Loss: 1.9994 - Train Accuracy: 0.3250 - Test Loss: 1.9854 - Test Accuracy: 0.3667\n",
      "Epoch 87/100 - Train Loss: 1.9994 - Train Accuracy: 0.3250 - Test Loss: 1.9854 - Test Accuracy: 0.3667\n",
      "Epoch 88/100 - Train Loss: 1.9994 - Train Accuracy: 0.3250 - Test Loss: 1.9854 - Test Accuracy: 0.3667\n",
      "Epoch 89/100 - Train Loss: 1.9994 - Train Accuracy: 0.3250 - Test Loss: 1.9854 - Test Accuracy: 0.3667\n",
      "Epoch 90/100 - Train Loss: 1.9994 - Train Accuracy: 0.3250 - Test Loss: 1.9854 - Test Accuracy: 0.3667\n",
      "Epoch 91/100 - Train Loss: 1.9994 - Train Accuracy: 0.3250 - Test Loss: 1.9854 - Test Accuracy: 0.3667\n",
      "Epoch 92/100 - Train Loss: 1.9994 - Train Accuracy: 0.3250 - Test Loss: 1.9854 - Test Accuracy: 0.3667\n",
      "Epoch 93/100 - Train Loss: 1.9994 - Train Accuracy: 0.3250 - Test Loss: 1.9854 - Test Accuracy: 0.3667\n",
      "Epoch 94/100 - Train Loss: 1.9994 - Train Accuracy: 0.3250 - Test Loss: 1.9854 - Test Accuracy: 0.3667\n",
      "Epoch 95/100 - Train Loss: 1.9994 - Train Accuracy: 0.3250 - Test Loss: 1.9854 - Test Accuracy: 0.3667\n",
      "Epoch 96/100 - Train Loss: 1.9994 - Train Accuracy: 0.3250 - Test Loss: 1.9854 - Test Accuracy: 0.3667\n",
      "Epoch 97/100 - Train Loss: 1.9994 - Train Accuracy: 0.3250 - Test Loss: 1.9854 - Test Accuracy: 0.3667\n",
      "Epoch 98/100 - Train Loss: 1.9994 - Train Accuracy: 0.3250 - Test Loss: 1.9854 - Test Accuracy: 0.3667\n",
      "Epoch 99/100 - Train Loss: 1.9994 - Train Accuracy: 0.3250 - Test Loss: 1.9854 - Test Accuracy: 0.3667\n",
      "Epoch 100/100 - Train Loss: 1.9994 - Train Accuracy: 0.3250 - Test Loss: 1.9854 - Test Accuracy: 0.3667\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "np.random.seed(0)\n",
    "import nnfs\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "nnfs.init()\n",
    "\n",
    "class LayerDense:\n",
    "    def __init__(self, n_inputs, n_neurons):\n",
    "        self.weights = 0.10 * np.random.randn(n_inputs, n_neurons)\n",
    "        self.biases = np.zeros((1, n_neurons))\n",
    "    def forward(self, inputs):\n",
    "        self.output = np.dot(inputs, self.weights) + self.biases\n",
    "\n",
    "class ActivationReLU:  \n",
    "    def forward(self, inputs):\n",
    "        self.output = np.maximum(0, inputs)\n",
    "\n",
    "class LossMultiClassSVM:\n",
    "    def forward(self, scores, y):\n",
    "        num_classes = scores.shape[1]\n",
    "        num_examples = scores.shape[0]\n",
    "        correct_class_scores = scores[np.arange(num_examples), y]\n",
    "        margins = np.maximum(0, scores - correct_class_scores[:, np.newaxis] + 1.0)\n",
    "        margins[np.arange(num_examples), y] = 0\n",
    "        loss = np.sum(margins) / num_examples\n",
    "        return loss\n",
    "\n",
    "class NeuralNetwork:\n",
    "    def __init__(self, layer_sizes):\n",
    "        self.layers = self.create_network(layer_sizes)\n",
    "        \n",
    "    def create_network(self, layer_sizes):\n",
    "        network = []\n",
    "        for i in range(1, len(layer_sizes)):\n",
    "            network.append(LayerDense(layer_sizes[i-1], layer_sizes[i]))\n",
    "            if i < len(layer_sizes) - 1:\n",
    "                network.append(ActivationReLU())\n",
    "        return network\n",
    "    \n",
    "    def forward(self, X):\n",
    "        for layer in self.layers:\n",
    "            layer.forward(X)\n",
    "            X = layer.output\n",
    "        return X\n",
    "\n",
    "def load_iris_dataset():\n",
    "    iris = load_iris()\n",
    "    X, y = iris.data, iris.target\n",
    "    return X, y\n",
    "\n",
    "def split_dataset(X, y, test_size=0.2, random_state=42):\n",
    "    return train_test_split(X, y, test_size=test_size, random_state=random_state)\n",
    "\n",
    "def calculate_accuracy(y_true, y_pred):\n",
    "    return np.mean(y_true == y_pred)\n",
    "\n",
    "def main():\n",
    "    X, y = load_iris_dataset()\n",
    "    X_train, X_test, y_train, y_test = split_dataset(X, y)\n",
    "    \n",
    "    num_features = X_train.shape[1]\n",
    "    num_classes = len(np.unique(y_train))\n",
    "\n",
    "    num_layers = int(input(\"Enter the number of layers: \"))\n",
    "    layer_neurons = [num_features]  # Input layer\n",
    "\n",
    "    for i in range(num_layers - 1):\n",
    "        neurons = int(input(f\"Enter the number of neurons in layer {i+1}: \"))\n",
    "        layer_neurons.append(neurons)\n",
    "\n",
    "    layer_neurons.append(num_classes)  # Output layer\n",
    "\n",
    "    neural_net = NeuralNetwork(layer_neurons)\n",
    "    loss_function = LossMultiClassSVM()\n",
    "    \n",
    "    num_epochs = int(input(\"Enter the number of epochs: \"))\n",
    "    learning_rate = float(input(\"Enter the learning rate: \"))\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        output_train = neural_net.forward(X_train)\n",
    "        train_loss = loss_function.forward(output_train, y_train)\n",
    "        train_accuracy = calculate_accuracy(y_train, np.argmax(output_train, axis=1))\n",
    "        \n",
    "        output_test = neural_net.forward(X_test)\n",
    "        test_loss = loss_function.forward(output_test, y_test)\n",
    "        test_accuracy = calculate_accuracy(y_test, np.argmax(output_test, axis=1))\n",
    "\n",
    "        print(f\"Epoch {epoch+1}/{num_epochs} - Train Loss: {train_loss:.4f} - Train Accuracy: {train_accuracy:.4f} - Test Loss: {test_loss:.4f} - Test Accuracy: {test_accuracy:.4f}\")\n",
    "\n",
    "        # Backpropagation and parameter updates would go here, but not included in this example\n",
    "    \n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4430734f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter the number of layers: 3\n",
      "Enter the number of neurons in layer 1: 8\n",
      "Enter the number of neurons in layer 2: 8\n",
      "Enter the number of epochs: 100\n",
      "Enter the learning rate: 0.001\n",
      "Epoch 1/100 - Train Loss: 1.9994 - Train Accuracy: 0.3250 - Test Loss: 1.9854 - Test Accuracy: 0.3667\n",
      "Epoch 2/100 - Train Loss: 1.9994 - Train Accuracy: 0.3250 - Test Loss: 1.9854 - Test Accuracy: 0.3667\n",
      "Epoch 3/100 - Train Loss: 1.9994 - Train Accuracy: 0.3250 - Test Loss: 1.9854 - Test Accuracy: 0.3667\n",
      "Epoch 4/100 - Train Loss: 1.9994 - Train Accuracy: 0.3250 - Test Loss: 1.9854 - Test Accuracy: 0.3667\n",
      "Epoch 5/100 - Train Loss: 1.9994 - Train Accuracy: 0.3250 - Test Loss: 1.9854 - Test Accuracy: 0.3667\n",
      "Epoch 6/100 - Train Loss: 1.9994 - Train Accuracy: 0.3250 - Test Loss: 1.9854 - Test Accuracy: 0.3667\n",
      "Epoch 7/100 - Train Loss: 1.9994 - Train Accuracy: 0.3250 - Test Loss: 1.9854 - Test Accuracy: 0.3667\n",
      "Epoch 8/100 - Train Loss: 1.9994 - Train Accuracy: 0.3250 - Test Loss: 1.9854 - Test Accuracy: 0.3667\n",
      "Epoch 9/100 - Train Loss: 1.9994 - Train Accuracy: 0.3250 - Test Loss: 1.9854 - Test Accuracy: 0.3667\n",
      "Epoch 10/100 - Train Loss: 1.9994 - Train Accuracy: 0.3250 - Test Loss: 1.9854 - Test Accuracy: 0.3667\n",
      "Epoch 11/100 - Train Loss: 1.9994 - Train Accuracy: 0.3250 - Test Loss: 1.9854 - Test Accuracy: 0.3667\n",
      "Epoch 12/100 - Train Loss: 1.9994 - Train Accuracy: 0.3250 - Test Loss: 1.9854 - Test Accuracy: 0.3667\n",
      "Epoch 13/100 - Train Loss: 1.9994 - Train Accuracy: 0.3250 - Test Loss: 1.9854 - Test Accuracy: 0.3667\n",
      "Epoch 14/100 - Train Loss: 1.9994 - Train Accuracy: 0.3250 - Test Loss: 1.9854 - Test Accuracy: 0.3667\n",
      "Epoch 15/100 - Train Loss: 1.9994 - Train Accuracy: 0.3250 - Test Loss: 1.9854 - Test Accuracy: 0.3667\n",
      "Epoch 16/100 - Train Loss: 1.9994 - Train Accuracy: 0.3250 - Test Loss: 1.9854 - Test Accuracy: 0.3667\n",
      "Epoch 17/100 - Train Loss: 1.9994 - Train Accuracy: 0.3250 - Test Loss: 1.9854 - Test Accuracy: 0.3667\n",
      "Epoch 18/100 - Train Loss: 1.9994 - Train Accuracy: 0.3250 - Test Loss: 1.9854 - Test Accuracy: 0.3667\n",
      "Epoch 19/100 - Train Loss: 1.9994 - Train Accuracy: 0.3250 - Test Loss: 1.9854 - Test Accuracy: 0.3667\n",
      "Epoch 20/100 - Train Loss: 1.9994 - Train Accuracy: 0.3250 - Test Loss: 1.9854 - Test Accuracy: 0.3667\n",
      "Epoch 21/100 - Train Loss: 1.9994 - Train Accuracy: 0.3250 - Test Loss: 1.9854 - Test Accuracy: 0.3667\n",
      "Epoch 22/100 - Train Loss: 1.9994 - Train Accuracy: 0.3250 - Test Loss: 1.9854 - Test Accuracy: 0.3667\n",
      "Epoch 23/100 - Train Loss: 1.9994 - Train Accuracy: 0.3250 - Test Loss: 1.9854 - Test Accuracy: 0.3667\n",
      "Epoch 24/100 - Train Loss: 1.9994 - Train Accuracy: 0.3250 - Test Loss: 1.9854 - Test Accuracy: 0.3667\n",
      "Epoch 25/100 - Train Loss: 1.9994 - Train Accuracy: 0.3250 - Test Loss: 1.9854 - Test Accuracy: 0.3667\n",
      "Epoch 26/100 - Train Loss: 1.9994 - Train Accuracy: 0.3250 - Test Loss: 1.9854 - Test Accuracy: 0.3667\n",
      "Epoch 27/100 - Train Loss: 1.9994 - Train Accuracy: 0.3250 - Test Loss: 1.9854 - Test Accuracy: 0.3667\n",
      "Epoch 28/100 - Train Loss: 1.9994 - Train Accuracy: 0.3250 - Test Loss: 1.9854 - Test Accuracy: 0.3667\n",
      "Epoch 29/100 - Train Loss: 1.9994 - Train Accuracy: 0.3250 - Test Loss: 1.9854 - Test Accuracy: 0.3667\n",
      "Epoch 30/100 - Train Loss: 1.9994 - Train Accuracy: 0.3250 - Test Loss: 1.9854 - Test Accuracy: 0.3667\n",
      "Epoch 31/100 - Train Loss: 1.9994 - Train Accuracy: 0.3250 - Test Loss: 1.9854 - Test Accuracy: 0.3667\n",
      "Epoch 32/100 - Train Loss: 1.9994 - Train Accuracy: 0.3250 - Test Loss: 1.9854 - Test Accuracy: 0.3667\n",
      "Epoch 33/100 - Train Loss: 1.9994 - Train Accuracy: 0.3250 - Test Loss: 1.9854 - Test Accuracy: 0.3667\n",
      "Epoch 34/100 - Train Loss: 1.9994 - Train Accuracy: 0.3250 - Test Loss: 1.9854 - Test Accuracy: 0.3667\n",
      "Epoch 35/100 - Train Loss: 1.9994 - Train Accuracy: 0.3250 - Test Loss: 1.9854 - Test Accuracy: 0.3667\n",
      "Epoch 36/100 - Train Loss: 1.9994 - Train Accuracy: 0.3250 - Test Loss: 1.9854 - Test Accuracy: 0.3667\n",
      "Epoch 37/100 - Train Loss: 1.9994 - Train Accuracy: 0.3250 - Test Loss: 1.9854 - Test Accuracy: 0.3667\n",
      "Epoch 38/100 - Train Loss: 1.9994 - Train Accuracy: 0.3250 - Test Loss: 1.9854 - Test Accuracy: 0.3667\n",
      "Epoch 39/100 - Train Loss: 1.9994 - Train Accuracy: 0.3250 - Test Loss: 1.9854 - Test Accuracy: 0.3667\n",
      "Epoch 40/100 - Train Loss: 1.9994 - Train Accuracy: 0.3250 - Test Loss: 1.9854 - Test Accuracy: 0.3667\n",
      "Epoch 41/100 - Train Loss: 1.9994 - Train Accuracy: 0.3250 - Test Loss: 1.9854 - Test Accuracy: 0.3667\n",
      "Epoch 42/100 - Train Loss: 1.9994 - Train Accuracy: 0.3250 - Test Loss: 1.9854 - Test Accuracy: 0.3667\n",
      "Epoch 43/100 - Train Loss: 1.9994 - Train Accuracy: 0.3250 - Test Loss: 1.9854 - Test Accuracy: 0.3667\n",
      "Epoch 44/100 - Train Loss: 1.9994 - Train Accuracy: 0.3250 - Test Loss: 1.9854 - Test Accuracy: 0.3667\n",
      "Epoch 45/100 - Train Loss: 1.9994 - Train Accuracy: 0.3250 - Test Loss: 1.9854 - Test Accuracy: 0.3667\n",
      "Epoch 46/100 - Train Loss: 1.9994 - Train Accuracy: 0.3250 - Test Loss: 1.9854 - Test Accuracy: 0.3667\n",
      "Epoch 47/100 - Train Loss: 1.9994 - Train Accuracy: 0.3250 - Test Loss: 1.9854 - Test Accuracy: 0.3667\n",
      "Epoch 48/100 - Train Loss: 1.9994 - Train Accuracy: 0.3250 - Test Loss: 1.9854 - Test Accuracy: 0.3667\n",
      "Epoch 49/100 - Train Loss: 1.9994 - Train Accuracy: 0.3250 - Test Loss: 1.9854 - Test Accuracy: 0.3667\n",
      "Epoch 50/100 - Train Loss: 1.9994 - Train Accuracy: 0.3250 - Test Loss: 1.9854 - Test Accuracy: 0.3667\n",
      "Epoch 51/100 - Train Loss: 1.9994 - Train Accuracy: 0.3250 - Test Loss: 1.9854 - Test Accuracy: 0.3667\n",
      "Epoch 52/100 - Train Loss: 1.9994 - Train Accuracy: 0.3250 - Test Loss: 1.9854 - Test Accuracy: 0.3667\n",
      "Epoch 53/100 - Train Loss: 1.9994 - Train Accuracy: 0.3250 - Test Loss: 1.9854 - Test Accuracy: 0.3667\n",
      "Epoch 54/100 - Train Loss: 1.9994 - Train Accuracy: 0.3250 - Test Loss: 1.9854 - Test Accuracy: 0.3667\n",
      "Epoch 55/100 - Train Loss: 1.9994 - Train Accuracy: 0.3250 - Test Loss: 1.9854 - Test Accuracy: 0.3667\n",
      "Epoch 56/100 - Train Loss: 1.9994 - Train Accuracy: 0.3250 - Test Loss: 1.9854 - Test Accuracy: 0.3667\n",
      "Epoch 57/100 - Train Loss: 1.9994 - Train Accuracy: 0.3250 - Test Loss: 1.9854 - Test Accuracy: 0.3667\n",
      "Epoch 58/100 - Train Loss: 1.9994 - Train Accuracy: 0.3250 - Test Loss: 1.9854 - Test Accuracy: 0.3667\n",
      "Epoch 59/100 - Train Loss: 1.9994 - Train Accuracy: 0.3250 - Test Loss: 1.9854 - Test Accuracy: 0.3667\n",
      "Epoch 60/100 - Train Loss: 1.9994 - Train Accuracy: 0.3250 - Test Loss: 1.9854 - Test Accuracy: 0.3667\n",
      "Epoch 61/100 - Train Loss: 1.9994 - Train Accuracy: 0.3250 - Test Loss: 1.9854 - Test Accuracy: 0.3667\n",
      "Epoch 62/100 - Train Loss: 1.9994 - Train Accuracy: 0.3250 - Test Loss: 1.9854 - Test Accuracy: 0.3667\n",
      "Epoch 63/100 - Train Loss: 1.9994 - Train Accuracy: 0.3250 - Test Loss: 1.9854 - Test Accuracy: 0.3667\n",
      "Epoch 64/100 - Train Loss: 1.9994 - Train Accuracy: 0.3250 - Test Loss: 1.9854 - Test Accuracy: 0.3667\n",
      "Epoch 65/100 - Train Loss: 1.9994 - Train Accuracy: 0.3250 - Test Loss: 1.9854 - Test Accuracy: 0.3667\n",
      "Epoch 66/100 - Train Loss: 1.9994 - Train Accuracy: 0.3250 - Test Loss: 1.9854 - Test Accuracy: 0.3667\n",
      "Epoch 67/100 - Train Loss: 1.9994 - Train Accuracy: 0.3250 - Test Loss: 1.9854 - Test Accuracy: 0.3667\n",
      "Epoch 68/100 - Train Loss: 1.9994 - Train Accuracy: 0.3250 - Test Loss: 1.9854 - Test Accuracy: 0.3667\n",
      "Epoch 69/100 - Train Loss: 1.9994 - Train Accuracy: 0.3250 - Test Loss: 1.9854 - Test Accuracy: 0.3667\n",
      "Epoch 70/100 - Train Loss: 1.9994 - Train Accuracy: 0.3250 - Test Loss: 1.9854 - Test Accuracy: 0.3667\n",
      "Epoch 71/100 - Train Loss: 1.9994 - Train Accuracy: 0.3250 - Test Loss: 1.9854 - Test Accuracy: 0.3667\n",
      "Epoch 72/100 - Train Loss: 1.9994 - Train Accuracy: 0.3250 - Test Loss: 1.9854 - Test Accuracy: 0.3667\n",
      "Epoch 73/100 - Train Loss: 1.9994 - Train Accuracy: 0.3250 - Test Loss: 1.9854 - Test Accuracy: 0.3667\n",
      "Epoch 74/100 - Train Loss: 1.9994 - Train Accuracy: 0.3250 - Test Loss: 1.9854 - Test Accuracy: 0.3667\n",
      "Epoch 75/100 - Train Loss: 1.9994 - Train Accuracy: 0.3250 - Test Loss: 1.9854 - Test Accuracy: 0.3667\n",
      "Epoch 76/100 - Train Loss: 1.9994 - Train Accuracy: 0.3250 - Test Loss: 1.9854 - Test Accuracy: 0.3667\n",
      "Epoch 77/100 - Train Loss: 1.9994 - Train Accuracy: 0.3250 - Test Loss: 1.9854 - Test Accuracy: 0.3667\n",
      "Epoch 78/100 - Train Loss: 1.9994 - Train Accuracy: 0.3250 - Test Loss: 1.9854 - Test Accuracy: 0.3667\n",
      "Epoch 79/100 - Train Loss: 1.9994 - Train Accuracy: 0.3250 - Test Loss: 1.9854 - Test Accuracy: 0.3667\n",
      "Epoch 80/100 - Train Loss: 1.9994 - Train Accuracy: 0.3250 - Test Loss: 1.9854 - Test Accuracy: 0.3667\n",
      "Epoch 81/100 - Train Loss: 1.9994 - Train Accuracy: 0.3250 - Test Loss: 1.9854 - Test Accuracy: 0.3667\n",
      "Epoch 82/100 - Train Loss: 1.9994 - Train Accuracy: 0.3250 - Test Loss: 1.9854 - Test Accuracy: 0.3667\n",
      "Epoch 83/100 - Train Loss: 1.9994 - Train Accuracy: 0.3250 - Test Loss: 1.9854 - Test Accuracy: 0.3667\n",
      "Epoch 84/100 - Train Loss: 1.9994 - Train Accuracy: 0.3250 - Test Loss: 1.9854 - Test Accuracy: 0.3667\n",
      "Epoch 85/100 - Train Loss: 1.9994 - Train Accuracy: 0.3250 - Test Loss: 1.9854 - Test Accuracy: 0.3667\n",
      "Epoch 86/100 - Train Loss: 1.9994 - Train Accuracy: 0.3250 - Test Loss: 1.9854 - Test Accuracy: 0.3667\n",
      "Epoch 87/100 - Train Loss: 1.9994 - Train Accuracy: 0.3250 - Test Loss: 1.9854 - Test Accuracy: 0.3667\n",
      "Epoch 88/100 - Train Loss: 1.9994 - Train Accuracy: 0.3250 - Test Loss: 1.9854 - Test Accuracy: 0.3667\n",
      "Epoch 89/100 - Train Loss: 1.9994 - Train Accuracy: 0.3250 - Test Loss: 1.9854 - Test Accuracy: 0.3667\n",
      "Epoch 90/100 - Train Loss: 1.9994 - Train Accuracy: 0.3250 - Test Loss: 1.9854 - Test Accuracy: 0.3667\n",
      "Epoch 91/100 - Train Loss: 1.9994 - Train Accuracy: 0.3250 - Test Loss: 1.9854 - Test Accuracy: 0.3667\n",
      "Epoch 92/100 - Train Loss: 1.9994 - Train Accuracy: 0.3250 - Test Loss: 1.9854 - Test Accuracy: 0.3667\n",
      "Epoch 93/100 - Train Loss: 1.9994 - Train Accuracy: 0.3250 - Test Loss: 1.9854 - Test Accuracy: 0.3667\n",
      "Epoch 94/100 - Train Loss: 1.9994 - Train Accuracy: 0.3250 - Test Loss: 1.9854 - Test Accuracy: 0.3667\n",
      "Epoch 95/100 - Train Loss: 1.9994 - Train Accuracy: 0.3250 - Test Loss: 1.9854 - Test Accuracy: 0.3667\n",
      "Epoch 96/100 - Train Loss: 1.9994 - Train Accuracy: 0.3250 - Test Loss: 1.9854 - Test Accuracy: 0.3667\n",
      "Epoch 97/100 - Train Loss: 1.9994 - Train Accuracy: 0.3250 - Test Loss: 1.9854 - Test Accuracy: 0.3667\n",
      "Epoch 98/100 - Train Loss: 1.9994 - Train Accuracy: 0.3250 - Test Loss: 1.9854 - Test Accuracy: 0.3667\n",
      "Epoch 99/100 - Train Loss: 1.9994 - Train Accuracy: 0.3250 - Test Loss: 1.9854 - Test Accuracy: 0.3667\n",
      "Epoch 100/100 - Train Loss: 1.9994 - Train Accuracy: 0.3250 - Test Loss: 1.9854 - Test Accuracy: 0.3667\n",
      "Total Loss: 398.4798\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "np.random.seed(0)\n",
    "import nnfs\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "nnfs.init()\n",
    "\n",
    "class LayerDense:\n",
    "    def __init__(self, n_inputs, n_neurons):\n",
    "        self.weights = 0.10 * np.random.randn(n_inputs, n_neurons)\n",
    "        self.biases = np.zeros((1, n_neurons))\n",
    "    def forward(self, inputs):\n",
    "        self.output = np.dot(inputs, self.weights) + self.biases\n",
    "\n",
    "class ActivationReLU:  \n",
    "    def forward(self, inputs):\n",
    "        self.output = np.maximum(0, inputs)\n",
    "\n",
    "class LossMultiClassSVM:\n",
    "    def forward(self, scores, y):\n",
    "        num_classes = scores.shape[1]\n",
    "        num_examples = scores.shape[0]\n",
    "        correct_class_scores = scores[np.arange(num_examples), y]\n",
    "        margins = np.maximum(0, scores - correct_class_scores[:, np.newaxis] + 1.0)\n",
    "        margins[np.arange(num_examples), y] = 0\n",
    "        loss = np.sum(margins) / num_examples\n",
    "        return loss\n",
    "\n",
    "class NeuralNetwork:\n",
    "    def __init__(self, layer_sizes):\n",
    "        self.layers = self.create_network(layer_sizes)\n",
    "        \n",
    "    def create_network(self, layer_sizes):\n",
    "        network = []\n",
    "        for i in range(1, len(layer_sizes)):\n",
    "            network.append(LayerDense(layer_sizes[i-1], layer_sizes[i]))\n",
    "            if i < len(layer_sizes) - 1:\n",
    "                network.append(ActivationReLU())\n",
    "        return network\n",
    "    \n",
    "    def forward(self, X):\n",
    "        for layer in self.layers:\n",
    "            layer.forward(X)\n",
    "            X = layer.output\n",
    "        return X\n",
    "\n",
    "def load_iris_dataset():\n",
    "    iris = load_iris()\n",
    "    X, y = iris.data, iris.target\n",
    "    return X, y\n",
    "\n",
    "def split_dataset(X, y, test_size=0.2, random_state=42):\n",
    "    return train_test_split(X, y, test_size=test_size, random_state=random_state)\n",
    "\n",
    "def calculate_accuracy(y_true, y_pred):\n",
    "    return np.mean(y_true == y_pred)\n",
    "\n",
    "def main():\n",
    "    X, y = load_iris_dataset()\n",
    "    X_train, X_test, y_train, y_test = split_dataset(X, y)\n",
    "    \n",
    "    num_features = X_train.shape[1]\n",
    "    num_classes = len(np.unique(y_train))\n",
    "\n",
    "    num_layers = int(input(\"Enter the number of layers: \"))\n",
    "    layer_neurons = [num_features]  # Input layer\n",
    "\n",
    "    for i in range(num_layers - 1):\n",
    "        neurons = int(input(f\"Enter the number of neurons in layer {i+1}: \"))\n",
    "        layer_neurons.append(neurons)\n",
    "\n",
    "    layer_neurons.append(num_classes)  # Output layer\n",
    "\n",
    "    neural_net = NeuralNetwork(layer_neurons)\n",
    "    loss_function = LossMultiClassSVM()\n",
    "    \n",
    "    num_epochs = int(input(\"Enter the number of epochs: \"))\n",
    "    learning_rate = float(input(\"Enter the learning rate: \"))\n",
    "\n",
    "    total_loss = 0.0\n",
    "    for epoch in range(num_epochs):\n",
    "        output_train = neural_net.forward(X_train)\n",
    "        train_loss = loss_function.forward(output_train, y_train)\n",
    "        train_accuracy = calculate_accuracy(y_train, np.argmax(output_train, axis=1))\n",
    "        \n",
    "        output_test = neural_net.forward(X_test)\n",
    "        test_loss = loss_function.forward(output_test, y_test)\n",
    "        test_accuracy = calculate_accuracy(y_test, np.argmax(output_test, axis=1))\n",
    "\n",
    "        print(f\"Epoch {epoch+1}/{num_epochs} - Train Loss: {train_loss:.4f} - Train Accuracy: {train_accuracy:.4f} - Test Loss: {test_loss:.4f} - Test Accuracy: {test_accuracy:.4f}\")\n",
    "\n",
    "        total_loss += train_loss + test_loss\n",
    "\n",
    "    print(f\"Total Loss: {total_loss:.4f}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "611906a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter the number of layers: 3\n",
      "Enter the number of neurons in layer 1: 8\n",
      "Enter the number of neurons in layer 2: 8\n",
      "Enter the number of epochs: 100\n",
      "Enter the learning rate: 0.001\n",
      "Epoch 1/100 - Train Loss: 1.9994 - Train Accuracy: 0.3250 - Test Loss: 1.9854 - Test Accuracy: 0.3667\n",
      "Epoch 2/100 - Train Loss: 1.9970 - Train Accuracy: 0.3250 - Test Loss: 1.9810 - Test Accuracy: 0.3667\n",
      "Epoch 3/100 - Train Loss: 1.9945 - Train Accuracy: 0.3250 - Test Loss: 1.9764 - Test Accuracy: 0.3667\n",
      "Epoch 4/100 - Train Loss: 1.9918 - Train Accuracy: 0.3250 - Test Loss: 1.9715 - Test Accuracy: 0.3667\n",
      "Epoch 5/100 - Train Loss: 1.9890 - Train Accuracy: 0.3250 - Test Loss: 1.9662 - Test Accuracy: 0.3667\n",
      "Epoch 6/100 - Train Loss: 1.9859 - Train Accuracy: 0.3250 - Test Loss: 1.9606 - Test Accuracy: 0.3667\n",
      "Epoch 7/100 - Train Loss: 1.9825 - Train Accuracy: 0.3250 - Test Loss: 1.9544 - Test Accuracy: 0.3667\n",
      "Epoch 8/100 - Train Loss: 1.9787 - Train Accuracy: 0.3250 - Test Loss: 1.9476 - Test Accuracy: 0.3667\n",
      "Epoch 9/100 - Train Loss: 1.9745 - Train Accuracy: 0.3250 - Test Loss: 1.9402 - Test Accuracy: 0.3667\n",
      "Epoch 10/100 - Train Loss: 1.9698 - Train Accuracy: 0.3250 - Test Loss: 1.9320 - Test Accuracy: 0.3667\n",
      "Epoch 11/100 - Train Loss: 1.9645 - Train Accuracy: 0.3250 - Test Loss: 1.9228 - Test Accuracy: 0.3667\n",
      "Epoch 12/100 - Train Loss: 1.9582 - Train Accuracy: 0.3250 - Test Loss: 1.9122 - Test Accuracy: 0.3667\n",
      "Epoch 13/100 - Train Loss: 1.9496 - Train Accuracy: 0.3250 - Test Loss: 1.8986 - Test Accuracy: 0.3667\n",
      "Epoch 14/100 - Train Loss: 1.9393 - Train Accuracy: 0.3250 - Test Loss: 1.8827 - Test Accuracy: 0.3667\n",
      "Epoch 15/100 - Train Loss: 1.9290 - Train Accuracy: 0.3250 - Test Loss: 1.8663 - Test Accuracy: 0.3667\n",
      "Epoch 16/100 - Train Loss: 1.9171 - Train Accuracy: 0.3250 - Test Loss: 1.8475 - Test Accuracy: 0.3667\n",
      "Epoch 17/100 - Train Loss: 1.9030 - Train Accuracy: 0.3250 - Test Loss: 1.8257 - Test Accuracy: 0.3667\n",
      "Epoch 18/100 - Train Loss: 1.8866 - Train Accuracy: 0.3250 - Test Loss: 1.8003 - Test Accuracy: 0.3667\n",
      "Epoch 19/100 - Train Loss: 1.8670 - Train Accuracy: 0.3250 - Test Loss: 1.7705 - Test Accuracy: 0.3667\n",
      "Epoch 20/100 - Train Loss: 1.8436 - Train Accuracy: 0.3250 - Test Loss: 1.7352 - Test Accuracy: 0.3667\n",
      "Epoch 21/100 - Train Loss: 1.8173 - Train Accuracy: 0.3250 - Test Loss: 1.6981 - Test Accuracy: 0.3667\n",
      "Epoch 22/100 - Train Loss: 1.8032 - Train Accuracy: 0.3250 - Test Loss: 1.6800 - Test Accuracy: 0.3667\n",
      "Epoch 23/100 - Train Loss: 1.7944 - Train Accuracy: 0.3250 - Test Loss: 1.6696 - Test Accuracy: 0.3667\n",
      "Epoch 24/100 - Train Loss: 1.7831 - Train Accuracy: 0.3250 - Test Loss: 1.6670 - Test Accuracy: 0.3667\n",
      "Epoch 25/100 - Train Loss: 1.7686 - Train Accuracy: 0.3250 - Test Loss: 1.6482 - Test Accuracy: 0.3667\n",
      "Epoch 26/100 - Train Loss: 1.7562 - Train Accuracy: 0.3250 - Test Loss: 1.6383 - Test Accuracy: 0.3667\n",
      "Epoch 27/100 - Train Loss: 1.7452 - Train Accuracy: 0.3250 - Test Loss: 1.6289 - Test Accuracy: 0.3667\n",
      "Epoch 28/100 - Train Loss: 1.7311 - Train Accuracy: 0.3250 - Test Loss: 1.6159 - Test Accuracy: 0.3667\n",
      "Epoch 29/100 - Train Loss: 1.7168 - Train Accuracy: 0.3250 - Test Loss: 1.6035 - Test Accuracy: 0.3667\n",
      "Epoch 30/100 - Train Loss: 1.7024 - Train Accuracy: 0.3250 - Test Loss: 1.5890 - Test Accuracy: 0.3667\n",
      "Epoch 31/100 - Train Loss: 1.6871 - Train Accuracy: 0.3250 - Test Loss: 1.5751 - Test Accuracy: 0.3667\n",
      "Epoch 32/100 - Train Loss: 1.6718 - Train Accuracy: 0.3250 - Test Loss: 1.5604 - Test Accuracy: 0.3667\n",
      "Epoch 33/100 - Train Loss: 1.6534 - Train Accuracy: 0.3250 - Test Loss: 1.5432 - Test Accuracy: 0.3667\n",
      "Epoch 34/100 - Train Loss: 1.6357 - Train Accuracy: 0.3250 - Test Loss: 1.5267 - Test Accuracy: 0.3667\n",
      "Epoch 35/100 - Train Loss: 1.6155 - Train Accuracy: 0.3250 - Test Loss: 1.5081 - Test Accuracy: 0.3667\n",
      "Epoch 36/100 - Train Loss: 1.5955 - Train Accuracy: 0.3250 - Test Loss: 1.4888 - Test Accuracy: 0.3667\n",
      "Epoch 37/100 - Train Loss: 1.5727 - Train Accuracy: 0.3333 - Test Loss: 1.4679 - Test Accuracy: 0.3667\n",
      "Epoch 38/100 - Train Loss: 1.5512 - Train Accuracy: 0.4333 - Test Loss: 1.4454 - Test Accuracy: 0.4000\n",
      "Epoch 39/100 - Train Loss: 1.5283 - Train Accuracy: 0.5833 - Test Loss: 1.4233 - Test Accuracy: 0.5333\n",
      "Epoch 40/100 - Train Loss: 1.5051 - Train Accuracy: 0.6250 - Test Loss: 1.4013 - Test Accuracy: 0.7000\n",
      "Epoch 41/100 - Train Loss: 1.4762 - Train Accuracy: 0.6500 - Test Loss: 1.3736 - Test Accuracy: 0.7000\n",
      "Epoch 42/100 - Train Loss: 1.4426 - Train Accuracy: 0.6583 - Test Loss: 1.3411 - Test Accuracy: 0.7000\n",
      "Epoch 43/100 - Train Loss: 1.4076 - Train Accuracy: 0.6583 - Test Loss: 1.3071 - Test Accuracy: 0.7000\n",
      "Epoch 44/100 - Train Loss: 1.3720 - Train Accuracy: 0.6583 - Test Loss: 1.2716 - Test Accuracy: 0.7000\n",
      "Epoch 45/100 - Train Loss: 1.3397 - Train Accuracy: 0.6583 - Test Loss: 1.2382 - Test Accuracy: 0.7000\n",
      "Epoch 46/100 - Train Loss: 1.3151 - Train Accuracy: 0.6583 - Test Loss: 1.2100 - Test Accuracy: 0.7000\n",
      "Epoch 47/100 - Train Loss: 1.2869 - Train Accuracy: 0.6583 - Test Loss: 1.1838 - Test Accuracy: 0.7000\n",
      "Epoch 48/100 - Train Loss: 1.2693 - Train Accuracy: 0.6583 - Test Loss: 1.1700 - Test Accuracy: 0.7000\n",
      "Epoch 49/100 - Train Loss: 1.2307 - Train Accuracy: 0.6583 - Test Loss: 1.1334 - Test Accuracy: 0.7000\n",
      "Epoch 50/100 - Train Loss: 1.2206 - Train Accuracy: 0.6583 - Test Loss: 1.1255 - Test Accuracy: 0.7000\n",
      "Epoch 51/100 - Train Loss: 1.1631 - Train Accuracy: 0.6583 - Test Loss: 1.0629 - Test Accuracy: 0.7000\n",
      "Epoch 52/100 - Train Loss: 1.1323 - Train Accuracy: 0.6583 - Test Loss: 1.0328 - Test Accuracy: 0.7000\n",
      "Epoch 53/100 - Train Loss: 1.0969 - Train Accuracy: 0.6583 - Test Loss: 1.0148 - Test Accuracy: 0.7000\n",
      "Epoch 54/100 - Train Loss: 1.0815 - Train Accuracy: 0.6583 - Test Loss: 0.9917 - Test Accuracy: 0.7000\n",
      "Epoch 55/100 - Train Loss: 1.0071 - Train Accuracy: 0.6583 - Test Loss: 0.9108 - Test Accuracy: 0.7000\n",
      "Epoch 56/100 - Train Loss: 0.9569 - Train Accuracy: 0.6583 - Test Loss: 0.8685 - Test Accuracy: 0.7000\n",
      "Epoch 57/100 - Train Loss: 0.9276 - Train Accuracy: 0.6583 - Test Loss: 0.8438 - Test Accuracy: 0.7000\n",
      "Epoch 58/100 - Train Loss: 0.8519 - Train Accuracy: 0.6583 - Test Loss: 0.7764 - Test Accuracy: 0.7000\n",
      "Epoch 59/100 - Train Loss: 0.8415 - Train Accuracy: 0.6583 - Test Loss: 0.7632 - Test Accuracy: 0.7000\n",
      "Epoch 60/100 - Train Loss: 0.7368 - Train Accuracy: 0.6583 - Test Loss: 0.6600 - Test Accuracy: 0.7000\n",
      "Epoch 61/100 - Train Loss: 0.7509 - Train Accuracy: 0.6583 - Test Loss: 0.6657 - Test Accuracy: 0.7000\n",
      "Epoch 62/100 - Train Loss: 0.6880 - Train Accuracy: 0.6583 - Test Loss: 0.6293 - Test Accuracy: 0.7000\n",
      "Epoch 63/100 - Train Loss: 0.7515 - Train Accuracy: 0.6583 - Test Loss: 0.6688 - Test Accuracy: 0.7000\n",
      "Epoch 64/100 - Train Loss: 0.6254 - Train Accuracy: 0.6583 - Test Loss: 0.5567 - Test Accuracy: 0.7000\n",
      "Epoch 65/100 - Train Loss: 0.6094 - Train Accuracy: 0.6583 - Test Loss: 0.5414 - Test Accuracy: 0.7000\n",
      "Epoch 66/100 - Train Loss: 0.6061 - Train Accuracy: 0.6583 - Test Loss: 0.5405 - Test Accuracy: 0.7000\n",
      "Epoch 67/100 - Train Loss: 0.5941 - Train Accuracy: 0.6583 - Test Loss: 0.5269 - Test Accuracy: 0.7000\n",
      "Epoch 68/100 - Train Loss: 0.5985 - Train Accuracy: 0.6583 - Test Loss: 0.5295 - Test Accuracy: 0.7000\n",
      "Epoch 69/100 - Train Loss: 0.5899 - Train Accuracy: 0.6583 - Test Loss: 0.5273 - Test Accuracy: 0.7000\n",
      "Epoch 70/100 - Train Loss: 0.5895 - Train Accuracy: 0.6583 - Test Loss: 0.5223 - Test Accuracy: 0.7000\n",
      "Epoch 71/100 - Train Loss: 0.5827 - Train Accuracy: 0.6583 - Test Loss: 0.5212 - Test Accuracy: 0.7000\n",
      "Epoch 72/100 - Train Loss: 0.5858 - Train Accuracy: 0.6583 - Test Loss: 0.5188 - Test Accuracy: 0.7000\n",
      "Epoch 73/100 - Train Loss: 0.5764 - Train Accuracy: 0.6583 - Test Loss: 0.5134 - Test Accuracy: 0.7000\n",
      "Epoch 74/100 - Train Loss: 0.5837 - Train Accuracy: 0.6583 - Test Loss: 0.5168 - Test Accuracy: 0.7000\n",
      "Epoch 75/100 - Train Loss: 0.5717 - Train Accuracy: 0.6583 - Test Loss: 0.5072 - Test Accuracy: 0.7000\n",
      "Epoch 76/100 - Train Loss: 0.5737 - Train Accuracy: 0.6583 - Test Loss: 0.5070 - Test Accuracy: 0.7000\n",
      "Epoch 77/100 - Train Loss: 0.5681 - Train Accuracy: 0.6583 - Test Loss: 0.5013 - Test Accuracy: 0.7000\n",
      "Epoch 78/100 - Train Loss: 0.5753 - Train Accuracy: 0.6583 - Test Loss: 0.5081 - Test Accuracy: 0.7000\n",
      "Epoch 79/100 - Train Loss: 0.5655 - Train Accuracy: 0.6583 - Test Loss: 0.4981 - Test Accuracy: 0.7000\n",
      "Epoch 80/100 - Train Loss: 0.5688 - Train Accuracy: 0.6583 - Test Loss: 0.5022 - Test Accuracy: 0.7000\n",
      "Epoch 81/100 - Train Loss: 0.5631 - Train Accuracy: 0.6583 - Test Loss: 0.4981 - Test Accuracy: 0.7000\n",
      "Epoch 82/100 - Train Loss: 0.5694 - Train Accuracy: 0.6583 - Test Loss: 0.5037 - Test Accuracy: 0.7000\n",
      "Epoch 83/100 - Train Loss: 0.5615 - Train Accuracy: 0.6583 - Test Loss: 0.4988 - Test Accuracy: 0.7000\n",
      "Epoch 84/100 - Train Loss: 0.5643 - Train Accuracy: 0.6583 - Test Loss: 0.5000 - Test Accuracy: 0.7000\n",
      "Epoch 85/100 - Train Loss: 0.5583 - Train Accuracy: 0.6583 - Test Loss: 0.4908 - Test Accuracy: 0.7000\n",
      "Epoch 86/100 - Train Loss: 0.5586 - Train Accuracy: 0.6583 - Test Loss: 0.4925 - Test Accuracy: 0.7000\n",
      "Epoch 87/100 - Train Loss: 0.5581 - Train Accuracy: 0.6583 - Test Loss: 0.4993 - Test Accuracy: 0.7000\n",
      "Epoch 88/100 - Train Loss: 0.5569 - Train Accuracy: 0.6583 - Test Loss: 0.4920 - Test Accuracy: 0.7000\n",
      "Epoch 89/100 - Train Loss: 0.5552 - Train Accuracy: 0.6583 - Test Loss: 0.4960 - Test Accuracy: 0.7000\n",
      "Epoch 90/100 - Train Loss: 0.5554 - Train Accuracy: 0.6583 - Test Loss: 0.4919 - Test Accuracy: 0.7000\n",
      "Epoch 91/100 - Train Loss: 0.5519 - Train Accuracy: 0.6583 - Test Loss: 0.4912 - Test Accuracy: 0.7000\n",
      "Epoch 92/100 - Train Loss: 0.5552 - Train Accuracy: 0.6583 - Test Loss: 0.4933 - Test Accuracy: 0.7000\n",
      "Epoch 93/100 - Train Loss: 0.5495 - Train Accuracy: 0.6583 - Test Loss: 0.4890 - Test Accuracy: 0.7000\n",
      "Epoch 94/100 - Train Loss: 0.5532 - Train Accuracy: 0.6583 - Test Loss: 0.4917 - Test Accuracy: 0.7000\n",
      "Epoch 95/100 - Train Loss: 0.5465 - Train Accuracy: 0.6583 - Test Loss: 0.4841 - Test Accuracy: 0.7000\n",
      "Epoch 96/100 - Train Loss: 0.5536 - Train Accuracy: 0.6583 - Test Loss: 0.4931 - Test Accuracy: 0.7000\n",
      "Epoch 97/100 - Train Loss: 0.5442 - Train Accuracy: 0.6583 - Test Loss: 0.4819 - Test Accuracy: 0.7000\n",
      "Epoch 98/100 - Train Loss: 0.5464 - Train Accuracy: 0.6583 - Test Loss: 0.4858 - Test Accuracy: 0.7000\n",
      "Epoch 99/100 - Train Loss: 0.5418 - Train Accuracy: 0.6583 - Test Loss: 0.4828 - Test Accuracy: 0.7000\n",
      "Epoch 100/100 - Train Loss: 0.5460 - Train Accuracy: 0.6583 - Test Loss: 0.4869 - Test Accuracy: 0.7000\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "np.random.seed(0)\n",
    "import nnfs\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "nnfs.init()\n",
    "\n",
    "class LayerDense:\n",
    "    def __init__(self, n_inputs, n_neurons):\n",
    "        self.weights = 0.10 * np.random.randn(n_inputs, n_neurons)\n",
    "        self.biases = np.zeros((1, n_neurons))\n",
    "    def forward(self, inputs):\n",
    "        self.inputs = inputs\n",
    "        self.output = np.dot(inputs, self.weights) + self.biases\n",
    "    def backward(self, dvalues):\n",
    "        self.dweights = np.dot(self.inputs.T, dvalues)\n",
    "        self.dbiases = np.sum(dvalues, axis=0, keepdims=True)\n",
    "        self.dinputs = np.dot(dvalues, self.weights.T)\n",
    "\n",
    "class ActivationReLU:  \n",
    "    def forward(self, inputs):\n",
    "        self.inputs = inputs\n",
    "        self.output = np.maximum(0, inputs)\n",
    "    def backward(self, dvalues):\n",
    "        self.dinputs = dvalues.copy()\n",
    "        self.dinputs[self.inputs <= 0] = 0\n",
    "\n",
    "class LossMultiClassSVM:\n",
    "    def forward(self, scores, y):\n",
    "        num_classes = scores.shape[1]\n",
    "        num_examples = scores.shape[0]\n",
    "        correct_class_scores = scores[np.arange(num_examples), y]\n",
    "        margins = np.maximum(0, scores - correct_class_scores[:, np.newaxis] + 1.0)\n",
    "        margins[np.arange(num_examples), y] = 0\n",
    "        loss = np.sum(margins) / num_examples\n",
    "        self.dvalues = np.zeros_like(scores)\n",
    "        self.dvalues[margins > 0] = 1\n",
    "        incorrect_counts = np.sum(self.dvalues, axis=1)\n",
    "        self.dvalues[np.arange(num_examples), y] = -incorrect_counts\n",
    "        return loss\n",
    "\n",
    "class NeuralNetwork:\n",
    "    def __init__(self, layer_sizes):\n",
    "        self.layers = self.create_network(layer_sizes)\n",
    "        \n",
    "    def create_network(self, layer_sizes):\n",
    "        network = []\n",
    "        for i in range(1, len(layer_sizes)):\n",
    "            network.append(LayerDense(layer_sizes[i-1], layer_sizes[i]))\n",
    "            if i < len(layer_sizes) - 1:\n",
    "                network.append(ActivationReLU())\n",
    "        return network\n",
    "    \n",
    "    def forward(self, X):\n",
    "        for layer in self.layers:\n",
    "            layer.forward(X)\n",
    "            X = layer.output\n",
    "        return X\n",
    "    \n",
    "    def backward(self, dvalues):\n",
    "        for layer in reversed(self.layers):\n",
    "            layer.backward(dvalues)\n",
    "            dvalues = layer.dinputs\n",
    "    \n",
    "    def update_params(self, learning_rate):\n",
    "        for layer in self.layers:\n",
    "            if isinstance(layer, LayerDense):\n",
    "                layer.weights -= learning_rate * layer.dweights\n",
    "                layer.biases -= learning_rate * layer.dbiases\n",
    "\n",
    "def load_iris_dataset():\n",
    "    iris = load_iris()\n",
    "    X, y = iris.data, iris.target\n",
    "    return X, y\n",
    "\n",
    "def split_dataset(X, y, test_size=0.2, random_state=42):\n",
    "    return train_test_split(X, y, test_size=test_size, random_state=random_state)\n",
    "\n",
    "def calculate_accuracy(y_true, y_pred):\n",
    "    return np.mean(y_true == y_pred)\n",
    "\n",
    "def main():\n",
    "    X, y = load_iris_dataset()\n",
    "    X_train, X_test, y_train, y_test = split_dataset(X, y)\n",
    "    \n",
    "    num_features = X_train.shape[1]\n",
    "    num_classes = len(np.unique(y_train))\n",
    "\n",
    "    num_layers = int(input(\"Enter the number of layers: \"))\n",
    "    layer_neurons = [num_features]  # Input layer\n",
    "\n",
    "    for i in range(num_layers - 1):\n",
    "        neurons = int(input(f\"Enter the number of neurons in layer {i+1}: \"))\n",
    "        layer_neurons.append(neurons)\n",
    "\n",
    "    layer_neurons.append(num_classes)  # Output layer\n",
    "\n",
    "    neural_net = NeuralNetwork(layer_neurons)\n",
    "    loss_function = LossMultiClassSVM()\n",
    "    \n",
    "    num_epochs = int(input(\"Enter the number of epochs: \"))\n",
    "    learning_rate = float(input(\"Enter the learning rate: \"))\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        output_train = neural_net.forward(X_train)\n",
    "        train_loss = loss_function.forward(output_train, y_train)\n",
    "        train_accuracy = calculate_accuracy(y_train, np.argmax(output_train, axis=1))\n",
    "        \n",
    "        output_test = neural_net.forward(X_test)\n",
    "        test_loss = loss_function.forward(output_test, y_test)\n",
    "        test_accuracy = calculate_accuracy(y_test, np.argmax(output_test, axis=1))\n",
    "\n",
    "        print(f\"Epoch {epoch+1}/{num_epochs} - Train Loss: {train_loss:.4f} - Train Accuracy: {train_accuracy:.4f} - Test Loss: {test_loss:.4f} - Test Accuracy: {test_accuracy:.4f}\")\n",
    "\n",
    "        dvalues = loss_function.dvalues\n",
    "        neural_net.backward(dvalues)\n",
    "        neural_net.update_params(learning_rate)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0098150f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter the number of layers: 3\n",
      "Enter the number of neurons in layer 1: 8\n",
      "Enter the number of neurons in layer 2: 8\n",
      "Enter the number of epochs: 150\n",
      "Enter the learning rate: 0.001\n",
      "Epoch 1/150 - Train Loss: 1.9994 - Train Accuracy: 0.3250 - Test Loss: 1.9854 - Test Accuracy: 0.3667\n",
      "Epoch 2/150 - Train Loss: 1.9970 - Train Accuracy: 0.3250 - Test Loss: 1.9810 - Test Accuracy: 0.3667\n",
      "Epoch 3/150 - Train Loss: 1.9945 - Train Accuracy: 0.3250 - Test Loss: 1.9764 - Test Accuracy: 0.3667\n",
      "Epoch 4/150 - Train Loss: 1.9918 - Train Accuracy: 0.3250 - Test Loss: 1.9715 - Test Accuracy: 0.3667\n",
      "Epoch 5/150 - Train Loss: 1.9890 - Train Accuracy: 0.3250 - Test Loss: 1.9662 - Test Accuracy: 0.3667\n",
      "Epoch 6/150 - Train Loss: 1.9859 - Train Accuracy: 0.3250 - Test Loss: 1.9606 - Test Accuracy: 0.3667\n",
      "Epoch 7/150 - Train Loss: 1.9825 - Train Accuracy: 0.3250 - Test Loss: 1.9544 - Test Accuracy: 0.3667\n",
      "Epoch 8/150 - Train Loss: 1.9787 - Train Accuracy: 0.3250 - Test Loss: 1.9476 - Test Accuracy: 0.3667\n",
      "Epoch 9/150 - Train Loss: 1.9745 - Train Accuracy: 0.3250 - Test Loss: 1.9402 - Test Accuracy: 0.3667\n",
      "Epoch 10/150 - Train Loss: 1.9698 - Train Accuracy: 0.3250 - Test Loss: 1.9320 - Test Accuracy: 0.3667\n",
      "Epoch 11/150 - Train Loss: 1.9645 - Train Accuracy: 0.3250 - Test Loss: 1.9228 - Test Accuracy: 0.3667\n",
      "Epoch 12/150 - Train Loss: 1.9582 - Train Accuracy: 0.3250 - Test Loss: 1.9122 - Test Accuracy: 0.3667\n",
      "Epoch 13/150 - Train Loss: 1.9496 - Train Accuracy: 0.3250 - Test Loss: 1.8986 - Test Accuracy: 0.3667\n",
      "Epoch 14/150 - Train Loss: 1.9393 - Train Accuracy: 0.3250 - Test Loss: 1.8827 - Test Accuracy: 0.3667\n",
      "Epoch 15/150 - Train Loss: 1.9290 - Train Accuracy: 0.3250 - Test Loss: 1.8663 - Test Accuracy: 0.3667\n",
      "Epoch 16/150 - Train Loss: 1.9171 - Train Accuracy: 0.3250 - Test Loss: 1.8475 - Test Accuracy: 0.3667\n",
      "Epoch 17/150 - Train Loss: 1.9030 - Train Accuracy: 0.3250 - Test Loss: 1.8257 - Test Accuracy: 0.3667\n",
      "Epoch 18/150 - Train Loss: 1.8866 - Train Accuracy: 0.3250 - Test Loss: 1.8003 - Test Accuracy: 0.3667\n",
      "Epoch 19/150 - Train Loss: 1.8670 - Train Accuracy: 0.3250 - Test Loss: 1.7705 - Test Accuracy: 0.3667\n",
      "Epoch 20/150 - Train Loss: 1.8436 - Train Accuracy: 0.3250 - Test Loss: 1.7352 - Test Accuracy: 0.3667\n",
      "Epoch 21/150 - Train Loss: 1.8173 - Train Accuracy: 0.3250 - Test Loss: 1.6981 - Test Accuracy: 0.3667\n",
      "Epoch 22/150 - Train Loss: 1.8032 - Train Accuracy: 0.3250 - Test Loss: 1.6800 - Test Accuracy: 0.3667\n",
      "Epoch 23/150 - Train Loss: 1.7944 - Train Accuracy: 0.3250 - Test Loss: 1.6696 - Test Accuracy: 0.3667\n",
      "Epoch 24/150 - Train Loss: 1.7831 - Train Accuracy: 0.3250 - Test Loss: 1.6670 - Test Accuracy: 0.3667\n",
      "Epoch 25/150 - Train Loss: 1.7686 - Train Accuracy: 0.3250 - Test Loss: 1.6482 - Test Accuracy: 0.3667\n",
      "Epoch 26/150 - Train Loss: 1.7562 - Train Accuracy: 0.3250 - Test Loss: 1.6383 - Test Accuracy: 0.3667\n",
      "Epoch 27/150 - Train Loss: 1.7452 - Train Accuracy: 0.3250 - Test Loss: 1.6289 - Test Accuracy: 0.3667\n",
      "Epoch 28/150 - Train Loss: 1.7311 - Train Accuracy: 0.3250 - Test Loss: 1.6159 - Test Accuracy: 0.3667\n",
      "Epoch 29/150 - Train Loss: 1.7168 - Train Accuracy: 0.3250 - Test Loss: 1.6035 - Test Accuracy: 0.3667\n",
      "Epoch 30/150 - Train Loss: 1.7024 - Train Accuracy: 0.3250 - Test Loss: 1.5890 - Test Accuracy: 0.3667\n",
      "Epoch 31/150 - Train Loss: 1.6871 - Train Accuracy: 0.3250 - Test Loss: 1.5751 - Test Accuracy: 0.3667\n",
      "Epoch 32/150 - Train Loss: 1.6718 - Train Accuracy: 0.3250 - Test Loss: 1.5604 - Test Accuracy: 0.3667\n",
      "Epoch 33/150 - Train Loss: 1.6534 - Train Accuracy: 0.3250 - Test Loss: 1.5432 - Test Accuracy: 0.3667\n",
      "Epoch 34/150 - Train Loss: 1.6357 - Train Accuracy: 0.3250 - Test Loss: 1.5267 - Test Accuracy: 0.3667\n",
      "Epoch 35/150 - Train Loss: 1.6155 - Train Accuracy: 0.3250 - Test Loss: 1.5081 - Test Accuracy: 0.3667\n",
      "Epoch 36/150 - Train Loss: 1.5955 - Train Accuracy: 0.3250 - Test Loss: 1.4888 - Test Accuracy: 0.3667\n",
      "Epoch 37/150 - Train Loss: 1.5727 - Train Accuracy: 0.3333 - Test Loss: 1.4679 - Test Accuracy: 0.3667\n",
      "Epoch 38/150 - Train Loss: 1.5512 - Train Accuracy: 0.4333 - Test Loss: 1.4454 - Test Accuracy: 0.4000\n",
      "Epoch 39/150 - Train Loss: 1.5283 - Train Accuracy: 0.5833 - Test Loss: 1.4233 - Test Accuracy: 0.5333\n",
      "Epoch 40/150 - Train Loss: 1.5051 - Train Accuracy: 0.6250 - Test Loss: 1.4013 - Test Accuracy: 0.7000\n",
      "Epoch 41/150 - Train Loss: 1.4762 - Train Accuracy: 0.6500 - Test Loss: 1.3736 - Test Accuracy: 0.7000\n",
      "Epoch 42/150 - Train Loss: 1.4426 - Train Accuracy: 0.6583 - Test Loss: 1.3411 - Test Accuracy: 0.7000\n",
      "Epoch 43/150 - Train Loss: 1.4076 - Train Accuracy: 0.6583 - Test Loss: 1.3071 - Test Accuracy: 0.7000\n",
      "Epoch 44/150 - Train Loss: 1.3720 - Train Accuracy: 0.6583 - Test Loss: 1.2716 - Test Accuracy: 0.7000\n",
      "Epoch 45/150 - Train Loss: 1.3397 - Train Accuracy: 0.6583 - Test Loss: 1.2382 - Test Accuracy: 0.7000\n",
      "Epoch 46/150 - Train Loss: 1.3151 - Train Accuracy: 0.6583 - Test Loss: 1.2100 - Test Accuracy: 0.7000\n",
      "Epoch 47/150 - Train Loss: 1.2869 - Train Accuracy: 0.6583 - Test Loss: 1.1838 - Test Accuracy: 0.7000\n",
      "Epoch 48/150 - Train Loss: 1.2693 - Train Accuracy: 0.6583 - Test Loss: 1.1700 - Test Accuracy: 0.7000\n",
      "Epoch 49/150 - Train Loss: 1.2307 - Train Accuracy: 0.6583 - Test Loss: 1.1334 - Test Accuracy: 0.7000\n",
      "Epoch 50/150 - Train Loss: 1.2206 - Train Accuracy: 0.6583 - Test Loss: 1.1255 - Test Accuracy: 0.7000\n",
      "Epoch 51/150 - Train Loss: 1.1631 - Train Accuracy: 0.6583 - Test Loss: 1.0629 - Test Accuracy: 0.7000\n",
      "Epoch 52/150 - Train Loss: 1.1323 - Train Accuracy: 0.6583 - Test Loss: 1.0328 - Test Accuracy: 0.7000\n",
      "Epoch 53/150 - Train Loss: 1.0969 - Train Accuracy: 0.6583 - Test Loss: 1.0148 - Test Accuracy: 0.7000\n",
      "Epoch 54/150 - Train Loss: 1.0815 - Train Accuracy: 0.6583 - Test Loss: 0.9917 - Test Accuracy: 0.7000\n",
      "Epoch 55/150 - Train Loss: 1.0071 - Train Accuracy: 0.6583 - Test Loss: 0.9108 - Test Accuracy: 0.7000\n",
      "Epoch 56/150 - Train Loss: 0.9569 - Train Accuracy: 0.6583 - Test Loss: 0.8685 - Test Accuracy: 0.7000\n",
      "Epoch 57/150 - Train Loss: 0.9276 - Train Accuracy: 0.6583 - Test Loss: 0.8438 - Test Accuracy: 0.7000\n",
      "Epoch 58/150 - Train Loss: 0.8519 - Train Accuracy: 0.6583 - Test Loss: 0.7764 - Test Accuracy: 0.7000\n",
      "Epoch 59/150 - Train Loss: 0.8415 - Train Accuracy: 0.6583 - Test Loss: 0.7632 - Test Accuracy: 0.7000\n",
      "Epoch 60/150 - Train Loss: 0.7368 - Train Accuracy: 0.6583 - Test Loss: 0.6600 - Test Accuracy: 0.7000\n",
      "Epoch 61/150 - Train Loss: 0.7509 - Train Accuracy: 0.6583 - Test Loss: 0.6657 - Test Accuracy: 0.7000\n",
      "Epoch 62/150 - Train Loss: 0.6880 - Train Accuracy: 0.6583 - Test Loss: 0.6293 - Test Accuracy: 0.7000\n",
      "Epoch 63/150 - Train Loss: 0.7515 - Train Accuracy: 0.6583 - Test Loss: 0.6688 - Test Accuracy: 0.7000\n",
      "Epoch 64/150 - Train Loss: 0.6254 - Train Accuracy: 0.6583 - Test Loss: 0.5567 - Test Accuracy: 0.7000\n",
      "Epoch 65/150 - Train Loss: 0.6094 - Train Accuracy: 0.6583 - Test Loss: 0.5414 - Test Accuracy: 0.7000\n",
      "Epoch 66/150 - Train Loss: 0.6061 - Train Accuracy: 0.6583 - Test Loss: 0.5405 - Test Accuracy: 0.7000\n",
      "Epoch 67/150 - Train Loss: 0.5941 - Train Accuracy: 0.6583 - Test Loss: 0.5269 - Test Accuracy: 0.7000\n",
      "Epoch 68/150 - Train Loss: 0.5985 - Train Accuracy: 0.6583 - Test Loss: 0.5295 - Test Accuracy: 0.7000\n",
      "Epoch 69/150 - Train Loss: 0.5899 - Train Accuracy: 0.6583 - Test Loss: 0.5273 - Test Accuracy: 0.7000\n",
      "Epoch 70/150 - Train Loss: 0.5895 - Train Accuracy: 0.6583 - Test Loss: 0.5223 - Test Accuracy: 0.7000\n",
      "Epoch 71/150 - Train Loss: 0.5827 - Train Accuracy: 0.6583 - Test Loss: 0.5212 - Test Accuracy: 0.7000\n",
      "Epoch 72/150 - Train Loss: 0.5858 - Train Accuracy: 0.6583 - Test Loss: 0.5188 - Test Accuracy: 0.7000\n",
      "Epoch 73/150 - Train Loss: 0.5764 - Train Accuracy: 0.6583 - Test Loss: 0.5134 - Test Accuracy: 0.7000\n",
      "Epoch 74/150 - Train Loss: 0.5837 - Train Accuracy: 0.6583 - Test Loss: 0.5168 - Test Accuracy: 0.7000\n",
      "Epoch 75/150 - Train Loss: 0.5717 - Train Accuracy: 0.6583 - Test Loss: 0.5072 - Test Accuracy: 0.7000\n",
      "Epoch 76/150 - Train Loss: 0.5737 - Train Accuracy: 0.6583 - Test Loss: 0.5070 - Test Accuracy: 0.7000\n",
      "Epoch 77/150 - Train Loss: 0.5681 - Train Accuracy: 0.6583 - Test Loss: 0.5013 - Test Accuracy: 0.7000\n",
      "Epoch 78/150 - Train Loss: 0.5753 - Train Accuracy: 0.6583 - Test Loss: 0.5081 - Test Accuracy: 0.7000\n",
      "Epoch 79/150 - Train Loss: 0.5655 - Train Accuracy: 0.6583 - Test Loss: 0.4981 - Test Accuracy: 0.7000\n",
      "Epoch 80/150 - Train Loss: 0.5688 - Train Accuracy: 0.6583 - Test Loss: 0.5022 - Test Accuracy: 0.7000\n",
      "Epoch 81/150 - Train Loss: 0.5631 - Train Accuracy: 0.6583 - Test Loss: 0.4981 - Test Accuracy: 0.7000\n",
      "Epoch 82/150 - Train Loss: 0.5694 - Train Accuracy: 0.6583 - Test Loss: 0.5037 - Test Accuracy: 0.7000\n",
      "Epoch 83/150 - Train Loss: 0.5615 - Train Accuracy: 0.6583 - Test Loss: 0.4988 - Test Accuracy: 0.7000\n",
      "Epoch 84/150 - Train Loss: 0.5643 - Train Accuracy: 0.6583 - Test Loss: 0.5000 - Test Accuracy: 0.7000\n",
      "Epoch 85/150 - Train Loss: 0.5583 - Train Accuracy: 0.6583 - Test Loss: 0.4908 - Test Accuracy: 0.7000\n",
      "Epoch 86/150 - Train Loss: 0.5586 - Train Accuracy: 0.6583 - Test Loss: 0.4925 - Test Accuracy: 0.7000\n",
      "Epoch 87/150 - Train Loss: 0.5581 - Train Accuracy: 0.6583 - Test Loss: 0.4993 - Test Accuracy: 0.7000\n",
      "Epoch 88/150 - Train Loss: 0.5569 - Train Accuracy: 0.6583 - Test Loss: 0.4920 - Test Accuracy: 0.7000\n",
      "Epoch 89/150 - Train Loss: 0.5552 - Train Accuracy: 0.6583 - Test Loss: 0.4960 - Test Accuracy: 0.7000\n",
      "Epoch 90/150 - Train Loss: 0.5554 - Train Accuracy: 0.6583 - Test Loss: 0.4919 - Test Accuracy: 0.7000\n",
      "Epoch 91/150 - Train Loss: 0.5519 - Train Accuracy: 0.6583 - Test Loss: 0.4912 - Test Accuracy: 0.7000\n",
      "Epoch 92/150 - Train Loss: 0.5552 - Train Accuracy: 0.6583 - Test Loss: 0.4933 - Test Accuracy: 0.7000\n",
      "Epoch 93/150 - Train Loss: 0.5495 - Train Accuracy: 0.6583 - Test Loss: 0.4890 - Test Accuracy: 0.7000\n",
      "Epoch 94/150 - Train Loss: 0.5532 - Train Accuracy: 0.6583 - Test Loss: 0.4917 - Test Accuracy: 0.7000\n",
      "Epoch 95/150 - Train Loss: 0.5465 - Train Accuracy: 0.6583 - Test Loss: 0.4841 - Test Accuracy: 0.7000\n",
      "Epoch 96/150 - Train Loss: 0.5536 - Train Accuracy: 0.6583 - Test Loss: 0.4931 - Test Accuracy: 0.7000\n",
      "Epoch 97/150 - Train Loss: 0.5442 - Train Accuracy: 0.6583 - Test Loss: 0.4819 - Test Accuracy: 0.7000\n",
      "Epoch 98/150 - Train Loss: 0.5464 - Train Accuracy: 0.6583 - Test Loss: 0.4858 - Test Accuracy: 0.7000\n",
      "Epoch 99/150 - Train Loss: 0.5418 - Train Accuracy: 0.6583 - Test Loss: 0.4828 - Test Accuracy: 0.7000\n",
      "Epoch 100/150 - Train Loss: 0.5460 - Train Accuracy: 0.6583 - Test Loss: 0.4869 - Test Accuracy: 0.7000\n",
      "Epoch 101/150 - Train Loss: 0.5390 - Train Accuracy: 0.6583 - Test Loss: 0.4793 - Test Accuracy: 0.7000\n",
      "Epoch 102/150 - Train Loss: 0.5450 - Train Accuracy: 0.6583 - Test Loss: 0.4863 - Test Accuracy: 0.7000\n",
      "Epoch 103/150 - Train Loss: 0.5363 - Train Accuracy: 0.6583 - Test Loss: 0.4758 - Test Accuracy: 0.7000\n",
      "Epoch 104/150 - Train Loss: 0.5385 - Train Accuracy: 0.6583 - Test Loss: 0.4801 - Test Accuracy: 0.7000\n",
      "Epoch 105/150 - Train Loss: 0.5330 - Train Accuracy: 0.6583 - Test Loss: 0.4720 - Test Accuracy: 0.7000\n",
      "Epoch 106/150 - Train Loss: 0.5354 - Train Accuracy: 0.6583 - Test Loss: 0.4781 - Test Accuracy: 0.7000\n",
      "Epoch 107/150 - Train Loss: 0.5316 - Train Accuracy: 0.6583 - Test Loss: 0.4762 - Test Accuracy: 0.7000\n",
      "Epoch 108/150 - Train Loss: 0.5338 - Train Accuracy: 0.6583 - Test Loss: 0.4775 - Test Accuracy: 0.7000\n",
      "Epoch 109/150 - Train Loss: 0.5278 - Train Accuracy: 0.6583 - Test Loss: 0.4709 - Test Accuracy: 0.7000\n",
      "Epoch 110/150 - Train Loss: 0.5335 - Train Accuracy: 0.6583 - Test Loss: 0.4786 - Test Accuracy: 0.7000\n",
      "Epoch 111/150 - Train Loss: 0.5250 - Train Accuracy: 0.6667 - Test Loss: 0.4680 - Test Accuracy: 0.7000\n",
      "Epoch 112/150 - Train Loss: 0.5316 - Train Accuracy: 0.6583 - Test Loss: 0.4767 - Test Accuracy: 0.7000\n",
      "Epoch 113/150 - Train Loss: 0.5214 - Train Accuracy: 0.6667 - Test Loss: 0.4635 - Test Accuracy: 0.7000\n",
      "Epoch 114/150 - Train Loss: 0.5212 - Train Accuracy: 0.6583 - Test Loss: 0.4648 - Test Accuracy: 0.7000\n",
      "Epoch 115/150 - Train Loss: 0.5197 - Train Accuracy: 0.6667 - Test Loss: 0.4669 - Test Accuracy: 0.7000\n",
      "Epoch 116/150 - Train Loss: 0.5218 - Train Accuracy: 0.6583 - Test Loss: 0.4694 - Test Accuracy: 0.7000\n",
      "Epoch 117/150 - Train Loss: 0.5161 - Train Accuracy: 0.6667 - Test Loss: 0.4631 - Test Accuracy: 0.7000\n",
      "Epoch 118/150 - Train Loss: 0.5200 - Train Accuracy: 0.6583 - Test Loss: 0.4682 - Test Accuracy: 0.7000\n",
      "Epoch 119/150 - Train Loss: 0.5125 - Train Accuracy: 0.6667 - Test Loss: 0.4593 - Test Accuracy: 0.7000\n",
      "Epoch 120/150 - Train Loss: 0.5182 - Train Accuracy: 0.6583 - Test Loss: 0.4669 - Test Accuracy: 0.7000\n",
      "Epoch 121/150 - Train Loss: 0.5084 - Train Accuracy: 0.6667 - Test Loss: 0.4539 - Test Accuracy: 0.7000\n",
      "Epoch 122/150 - Train Loss: 0.5074 - Train Accuracy: 0.6667 - Test Loss: 0.4537 - Test Accuracy: 0.7000\n",
      "Epoch 123/150 - Train Loss: 0.5097 - Train Accuracy: 0.6917 - Test Loss: 0.4640 - Test Accuracy: 0.7333\n",
      "Epoch 124/150 - Train Loss: 0.5045 - Train Accuracy: 0.6667 - Test Loss: 0.4527 - Test Accuracy: 0.7000\n",
      "Epoch 125/150 - Train Loss: 0.5023 - Train Accuracy: 0.6833 - Test Loss: 0.4525 - Test Accuracy: 0.7000\n",
      "Epoch 126/150 - Train Loss: 0.5068 - Train Accuracy: 0.6667 - Test Loss: 0.4593 - Test Accuracy: 0.7000\n",
      "Epoch 127/150 - Train Loss: 0.4985 - Train Accuracy: 0.6917 - Test Loss: 0.4494 - Test Accuracy: 0.7333\n",
      "Epoch 128/150 - Train Loss: 0.5034 - Train Accuracy: 0.6667 - Test Loss: 0.4559 - Test Accuracy: 0.7000\n",
      "Epoch 129/150 - Train Loss: 0.4944 - Train Accuracy: 0.6917 - Test Loss: 0.4455 - Test Accuracy: 0.7333\n",
      "Epoch 130/150 - Train Loss: 0.5009 - Train Accuracy: 0.6667 - Test Loss: 0.4540 - Test Accuracy: 0.7000\n",
      "Epoch 131/150 - Train Loss: 0.4896 - Train Accuracy: 0.6917 - Test Loss: 0.4399 - Test Accuracy: 0.7333\n",
      "Epoch 132/150 - Train Loss: 0.4925 - Train Accuracy: 0.6667 - Test Loss: 0.4460 - Test Accuracy: 0.7000\n",
      "Epoch 133/150 - Train Loss: 0.4878 - Train Accuracy: 0.7000 - Test Loss: 0.4434 - Test Accuracy: 0.7333\n",
      "Epoch 134/150 - Train Loss: 0.4894 - Train Accuracy: 0.6750 - Test Loss: 0.4438 - Test Accuracy: 0.7000\n",
      "Epoch 135/150 - Train Loss: 0.4824 - Train Accuracy: 0.7000 - Test Loss: 0.4374 - Test Accuracy: 0.7333\n",
      "Epoch 136/150 - Train Loss: 0.4878 - Train Accuracy: 0.6750 - Test Loss: 0.4431 - Test Accuracy: 0.7000\n",
      "Epoch 137/150 - Train Loss: 0.4779 - Train Accuracy: 0.7000 - Test Loss: 0.4334 - Test Accuracy: 0.7333\n",
      "Epoch 138/150 - Train Loss: 0.4845 - Train Accuracy: 0.6750 - Test Loss: 0.4405 - Test Accuracy: 0.7000\n",
      "Epoch 139/150 - Train Loss: 0.4712 - Train Accuracy: 0.7000 - Test Loss: 0.4257 - Test Accuracy: 0.7333\n",
      "Epoch 140/150 - Train Loss: 0.4692 - Train Accuracy: 0.7000 - Test Loss: 0.4235 - Test Accuracy: 0.7333\n",
      "Epoch 141/150 - Train Loss: 0.4683 - Train Accuracy: 0.6917 - Test Loss: 0.4255 - Test Accuracy: 0.7333\n",
      "Epoch 142/150 - Train Loss: 0.4647 - Train Accuracy: 0.7083 - Test Loss: 0.4207 - Test Accuracy: 0.7667\n",
      "Epoch 143/150 - Train Loss: 0.4683 - Train Accuracy: 0.6917 - Test Loss: 0.4289 - Test Accuracy: 0.7333\n",
      "Epoch 144/150 - Train Loss: 0.4634 - Train Accuracy: 0.7917 - Test Loss: 0.4262 - Test Accuracy: 0.8000\n",
      "Epoch 145/150 - Train Loss: 0.4630 - Train Accuracy: 0.6917 - Test Loss: 0.4237 - Test Accuracy: 0.7333\n",
      "Epoch 146/150 - Train Loss: 0.4571 - Train Accuracy: 0.8000 - Test Loss: 0.4199 - Test Accuracy: 0.8000\n",
      "Epoch 147/150 - Train Loss: 0.4600 - Train Accuracy: 0.6917 - Test Loss: 0.4218 - Test Accuracy: 0.7333\n",
      "Epoch 148/150 - Train Loss: 0.4518 - Train Accuracy: 0.8167 - Test Loss: 0.4159 - Test Accuracy: 0.8000\n",
      "Epoch 149/150 - Train Loss: 0.4549 - Train Accuracy: 0.6917 - Test Loss: 0.4176 - Test Accuracy: 0.7333\n",
      "Epoch 150/150 - Train Loss: 0.4424 - Train Accuracy: 0.8000 - Test Loss: 0.4036 - Test Accuracy: 0.8000\n",
      "Total Train Loss: 0.9605 - Total Train Accuracy: 0.5826 - Total Test Loss: 0.8930 - Total Test Accuracy: 0.6209\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "np.random.seed(0)\n",
    "import nnfs\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "nnfs.init()\n",
    "\n",
    "class LayerDense:\n",
    "    def __init__(self, n_inputs, n_neurons):\n",
    "        self.weights = 0.10 * np.random.randn(n_inputs, n_neurons)\n",
    "        self.biases = np.zeros((1, n_neurons))\n",
    "    def forward(self, inputs):\n",
    "        self.inputs = inputs\n",
    "        self.output = np.dot(inputs, self.weights) + self.biases\n",
    "    def backward(self, dvalues):\n",
    "        self.dweights = np.dot(self.inputs.T, dvalues)\n",
    "        self.dbiases = np.sum(dvalues, axis=0, keepdims=True)\n",
    "        self.dinputs = np.dot(dvalues, self.weights.T)\n",
    "\n",
    "class ActivationReLU:  \n",
    "    def forward(self, inputs):\n",
    "        self.inputs = inputs\n",
    "        self.output = np.maximum(0, inputs)\n",
    "    def backward(self, dvalues):\n",
    "        self.dinputs = dvalues.copy()\n",
    "        self.dinputs[self.inputs <= 0] = 0\n",
    "\n",
    "class LossMultiClassSVM:\n",
    "    def forward(self, scores, y):\n",
    "        num_classes = scores.shape[1]\n",
    "        num_examples = scores.shape[0]\n",
    "        correct_class_scores = scores[np.arange(num_examples), y]\n",
    "        margins = np.maximum(0, scores - correct_class_scores[:, np.newaxis] + 1.0)\n",
    "        margins[np.arange(num_examples), y] = 0\n",
    "        loss = np.sum(margins) / num_examples\n",
    "        self.dvalues = np.zeros_like(scores)\n",
    "        self.dvalues[margins > 0] = 1\n",
    "        incorrect_counts = np.sum(self.dvalues, axis=1)\n",
    "        self.dvalues[np.arange(num_examples), y] = -incorrect_counts\n",
    "        return loss\n",
    "\n",
    "class NeuralNetwork:\n",
    "    def __init__(self, layer_sizes):\n",
    "        self.layers = self.create_network(layer_sizes)\n",
    "        \n",
    "    def create_network(self, layer_sizes):\n",
    "        network = []\n",
    "        for i in range(1, len(layer_sizes)):\n",
    "            network.append(LayerDense(layer_sizes[i-1], layer_sizes[i]))\n",
    "            if i < len(layer_sizes) - 1:\n",
    "                network.append(ActivationReLU())\n",
    "        return network\n",
    "    \n",
    "    def forward(self, X):\n",
    "        for layer in self.layers:\n",
    "            layer.forward(X)\n",
    "            X = layer.output\n",
    "        return X\n",
    "    \n",
    "    def backward(self, dvalues):\n",
    "        for layer in reversed(self.layers):\n",
    "            layer.backward(dvalues)\n",
    "            dvalues = layer.dinputs\n",
    "    \n",
    "    def update_params(self, learning_rate):\n",
    "        for layer in self.layers:\n",
    "            if isinstance(layer, LayerDense):\n",
    "                layer.weights -= learning_rate * layer.dweights\n",
    "                layer.biases -= learning_rate * layer.dbiases\n",
    "\n",
    "def load_iris_dataset():\n",
    "    iris = load_iris()\n",
    "    X, y = iris.data, iris.target\n",
    "    return X, y\n",
    "\n",
    "def split_dataset(X, y, test_size=0.2, random_state=42):\n",
    "    return train_test_split(X, y, test_size=test_size, random_state=random_state)\n",
    "\n",
    "def calculate_accuracy(y_true, y_pred):\n",
    "    return np.mean(y_true == y_pred)\n",
    "\n",
    "def main():\n",
    "    X, y = load_iris_dataset()\n",
    "    X_train, X_test, y_train, y_test = split_dataset(X, y)\n",
    "    \n",
    "    num_features = X_train.shape[1]\n",
    "    num_classes = len(np.unique(y_train))\n",
    "\n",
    "    num_layers = int(input(\"Enter the number of layers: \"))\n",
    "    layer_neurons = [num_features]  # Input layer\n",
    "\n",
    "    for i in range(num_layers - 1):\n",
    "        neurons = int(input(f\"Enter the number of neurons in layer {i+1}: \"))\n",
    "        layer_neurons.append(neurons)\n",
    "\n",
    "    layer_neurons.append(num_classes)  # Output layer\n",
    "\n",
    "    neural_net = NeuralNetwork(layer_neurons)\n",
    "    loss_function = LossMultiClassSVM()\n",
    "    \n",
    "    num_epochs = int(input(\"Enter the number of epochs: \"))\n",
    "    learning_rate = float(input(\"Enter the learning rate: \"))\n",
    "\n",
    "    total_train_loss = 0.0\n",
    "    total_test_loss = 0.0\n",
    "    total_train_accuracy = 0.0\n",
    "    total_test_accuracy = 0.0\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        output_train = neural_net.forward(X_train)\n",
    "        train_loss = loss_function.forward(output_train, y_train)\n",
    "        train_accuracy = calculate_accuracy(y_train, np.argmax(output_train, axis=1))\n",
    "        \n",
    "        output_test = neural_net.forward(X_test)\n",
    "        test_loss = loss_function.forward(output_test, y_test)\n",
    "        test_accuracy = calculate_accuracy(y_test, np.argmax(output_test, axis=1))\n",
    "\n",
    "        print(f\"Epoch {epoch+1}/{num_epochs} - Train Loss: {train_loss:.4f} - Train Accuracy: {train_accuracy:.4f} - Test Loss: {test_loss:.4f} - Test Accuracy: {test_accuracy:.4f}\")\n",
    "\n",
    "        total_train_loss += train_loss\n",
    "        total_test_loss += test_loss\n",
    "        total_train_accuracy += train_accuracy\n",
    "        total_test_accuracy += test_accuracy\n",
    "\n",
    "        dvalues = loss_function.dvalues\n",
    "        neural_net.backward(dvalues)\n",
    "        neural_net.update_params(learning_rate)\n",
    "\n",
    "    total_train_loss /= num_epochs\n",
    "    total_test_loss /= num_epochs\n",
    "    total_train_accuracy /= num_epochs\n",
    "    total_test_accuracy /= num_epochs\n",
    "\n",
    "    print(f\"Total Train Loss: {total_train_loss:.4f} - Total Train Accuracy: {total_train_accuracy:.4f} - Total Test Loss: {total_test_loss:.4f} - Total Test Accuracy: {total_test_accuracy:.4f}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "5d043060",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter the number of layers: 3\n",
      "Enter the number of neurons in layer 1: 8\n",
      "Enter the number of neurons in layer 2: 8\n",
      "Enter the number of epochs: 100\n",
      "Enter the learning rate: 0.001\n",
      "Epoch 1/100 - Train Loss: 1.9994 - Train Accuracy: 0.3250 - Test Loss: 1.9854 - Test Accuracy: 0.3667\n",
      "Epoch 2/100 - Train Loss: 1.9970 - Train Accuracy: 0.3250 - Test Loss: 1.9810 - Test Accuracy: 0.3667\n",
      "Epoch 3/100 - Train Loss: 1.9945 - Train Accuracy: 0.3250 - Test Loss: 1.9764 - Test Accuracy: 0.3667\n",
      "Epoch 4/100 - Train Loss: 1.9918 - Train Accuracy: 0.3250 - Test Loss: 1.9715 - Test Accuracy: 0.3667\n",
      "Epoch 5/100 - Train Loss: 1.9890 - Train Accuracy: 0.3250 - Test Loss: 1.9662 - Test Accuracy: 0.3667\n",
      "Epoch 6/100 - Train Loss: 1.9859 - Train Accuracy: 0.3250 - Test Loss: 1.9606 - Test Accuracy: 0.3667\n",
      "Epoch 7/100 - Train Loss: 1.9825 - Train Accuracy: 0.3250 - Test Loss: 1.9544 - Test Accuracy: 0.3667\n",
      "Epoch 8/100 - Train Loss: 1.9787 - Train Accuracy: 0.3250 - Test Loss: 1.9476 - Test Accuracy: 0.3667\n",
      "Epoch 9/100 - Train Loss: 1.9745 - Train Accuracy: 0.3250 - Test Loss: 1.9402 - Test Accuracy: 0.3667\n",
      "Epoch 10/100 - Train Loss: 1.9698 - Train Accuracy: 0.3250 - Test Loss: 1.9320 - Test Accuracy: 0.3667\n",
      "Epoch 11/100 - Train Loss: 1.9645 - Train Accuracy: 0.3250 - Test Loss: 1.9228 - Test Accuracy: 0.3667\n",
      "Epoch 12/100 - Train Loss: 1.9582 - Train Accuracy: 0.3250 - Test Loss: 1.9122 - Test Accuracy: 0.3667\n",
      "Epoch 13/100 - Train Loss: 1.9496 - Train Accuracy: 0.3250 - Test Loss: 1.8986 - Test Accuracy: 0.3667\n",
      "Epoch 14/100 - Train Loss: 1.9393 - Train Accuracy: 0.3250 - Test Loss: 1.8827 - Test Accuracy: 0.3667\n",
      "Epoch 15/100 - Train Loss: 1.9290 - Train Accuracy: 0.3250 - Test Loss: 1.8663 - Test Accuracy: 0.3667\n",
      "Epoch 16/100 - Train Loss: 1.9171 - Train Accuracy: 0.3250 - Test Loss: 1.8475 - Test Accuracy: 0.3667\n",
      "Epoch 17/100 - Train Loss: 1.9030 - Train Accuracy: 0.3250 - Test Loss: 1.8257 - Test Accuracy: 0.3667\n",
      "Epoch 18/100 - Train Loss: 1.8866 - Train Accuracy: 0.3250 - Test Loss: 1.8003 - Test Accuracy: 0.3667\n",
      "Epoch 19/100 - Train Loss: 1.8670 - Train Accuracy: 0.3250 - Test Loss: 1.7705 - Test Accuracy: 0.3667\n",
      "Epoch 20/100 - Train Loss: 1.8436 - Train Accuracy: 0.3250 - Test Loss: 1.7352 - Test Accuracy: 0.3667\n",
      "Epoch 21/100 - Train Loss: 1.8173 - Train Accuracy: 0.3250 - Test Loss: 1.6981 - Test Accuracy: 0.3667\n",
      "Epoch 22/100 - Train Loss: 1.8032 - Train Accuracy: 0.3250 - Test Loss: 1.6800 - Test Accuracy: 0.3667\n",
      "Epoch 23/100 - Train Loss: 1.7944 - Train Accuracy: 0.3250 - Test Loss: 1.6696 - Test Accuracy: 0.3667\n",
      "Epoch 24/100 - Train Loss: 1.7831 - Train Accuracy: 0.3250 - Test Loss: 1.6670 - Test Accuracy: 0.3667\n",
      "Epoch 25/100 - Train Loss: 1.7686 - Train Accuracy: 0.3250 - Test Loss: 1.6482 - Test Accuracy: 0.3667\n",
      "Epoch 26/100 - Train Loss: 1.7562 - Train Accuracy: 0.3250 - Test Loss: 1.6383 - Test Accuracy: 0.3667\n",
      "Epoch 27/100 - Train Loss: 1.7452 - Train Accuracy: 0.3250 - Test Loss: 1.6289 - Test Accuracy: 0.3667\n",
      "Epoch 28/100 - Train Loss: 1.7311 - Train Accuracy: 0.3250 - Test Loss: 1.6159 - Test Accuracy: 0.3667\n",
      "Epoch 29/100 - Train Loss: 1.7168 - Train Accuracy: 0.3250 - Test Loss: 1.6035 - Test Accuracy: 0.3667\n",
      "Epoch 30/100 - Train Loss: 1.7024 - Train Accuracy: 0.3250 - Test Loss: 1.5890 - Test Accuracy: 0.3667\n",
      "Epoch 31/100 - Train Loss: 1.6871 - Train Accuracy: 0.3250 - Test Loss: 1.5751 - Test Accuracy: 0.3667\n",
      "Epoch 32/100 - Train Loss: 1.6718 - Train Accuracy: 0.3250 - Test Loss: 1.5604 - Test Accuracy: 0.3667\n",
      "Epoch 33/100 - Train Loss: 1.6534 - Train Accuracy: 0.3250 - Test Loss: 1.5432 - Test Accuracy: 0.3667\n",
      "Epoch 34/100 - Train Loss: 1.6357 - Train Accuracy: 0.3250 - Test Loss: 1.5267 - Test Accuracy: 0.3667\n",
      "Epoch 35/100 - Train Loss: 1.6155 - Train Accuracy: 0.3250 - Test Loss: 1.5081 - Test Accuracy: 0.3667\n",
      "Epoch 36/100 - Train Loss: 1.5955 - Train Accuracy: 0.3250 - Test Loss: 1.4888 - Test Accuracy: 0.3667\n",
      "Epoch 37/100 - Train Loss: 1.5727 - Train Accuracy: 0.3333 - Test Loss: 1.4679 - Test Accuracy: 0.3667\n",
      "Epoch 38/100 - Train Loss: 1.5512 - Train Accuracy: 0.4333 - Test Loss: 1.4454 - Test Accuracy: 0.4000\n",
      "Epoch 39/100 - Train Loss: 1.5283 - Train Accuracy: 0.5833 - Test Loss: 1.4233 - Test Accuracy: 0.5333\n",
      "Epoch 40/100 - Train Loss: 1.5051 - Train Accuracy: 0.6250 - Test Loss: 1.4013 - Test Accuracy: 0.7000\n",
      "Epoch 41/100 - Train Loss: 1.4762 - Train Accuracy: 0.6500 - Test Loss: 1.3736 - Test Accuracy: 0.7000\n",
      "Epoch 42/100 - Train Loss: 1.4426 - Train Accuracy: 0.6583 - Test Loss: 1.3411 - Test Accuracy: 0.7000\n",
      "Epoch 43/100 - Train Loss: 1.4076 - Train Accuracy: 0.6583 - Test Loss: 1.3071 - Test Accuracy: 0.7000\n",
      "Epoch 44/100 - Train Loss: 1.3720 - Train Accuracy: 0.6583 - Test Loss: 1.2716 - Test Accuracy: 0.7000\n",
      "Epoch 45/100 - Train Loss: 1.3397 - Train Accuracy: 0.6583 - Test Loss: 1.2382 - Test Accuracy: 0.7000\n",
      "Epoch 46/100 - Train Loss: 1.3151 - Train Accuracy: 0.6583 - Test Loss: 1.2100 - Test Accuracy: 0.7000\n",
      "Epoch 47/100 - Train Loss: 1.2869 - Train Accuracy: 0.6583 - Test Loss: 1.1838 - Test Accuracy: 0.7000\n",
      "Epoch 48/100 - Train Loss: 1.2693 - Train Accuracy: 0.6583 - Test Loss: 1.1700 - Test Accuracy: 0.7000\n",
      "Epoch 49/100 - Train Loss: 1.2307 - Train Accuracy: 0.6583 - Test Loss: 1.1334 - Test Accuracy: 0.7000\n",
      "Epoch 50/100 - Train Loss: 1.2206 - Train Accuracy: 0.6583 - Test Loss: 1.1255 - Test Accuracy: 0.7000\n",
      "Epoch 51/100 - Train Loss: 1.1631 - Train Accuracy: 0.6583 - Test Loss: 1.0629 - Test Accuracy: 0.7000\n",
      "Epoch 52/100 - Train Loss: 1.1323 - Train Accuracy: 0.6583 - Test Loss: 1.0328 - Test Accuracy: 0.7000\n",
      "Epoch 53/100 - Train Loss: 1.0969 - Train Accuracy: 0.6583 - Test Loss: 1.0148 - Test Accuracy: 0.7000\n",
      "Epoch 54/100 - Train Loss: 1.0815 - Train Accuracy: 0.6583 - Test Loss: 0.9917 - Test Accuracy: 0.7000\n",
      "Epoch 55/100 - Train Loss: 1.0071 - Train Accuracy: 0.6583 - Test Loss: 0.9108 - Test Accuracy: 0.7000\n",
      "Epoch 56/100 - Train Loss: 0.9569 - Train Accuracy: 0.6583 - Test Loss: 0.8685 - Test Accuracy: 0.7000\n",
      "Epoch 57/100 - Train Loss: 0.9276 - Train Accuracy: 0.6583 - Test Loss: 0.8438 - Test Accuracy: 0.7000\n",
      "Epoch 58/100 - Train Loss: 0.8519 - Train Accuracy: 0.6583 - Test Loss: 0.7764 - Test Accuracy: 0.7000\n",
      "Epoch 59/100 - Train Loss: 0.8415 - Train Accuracy: 0.6583 - Test Loss: 0.7632 - Test Accuracy: 0.7000\n",
      "Epoch 60/100 - Train Loss: 0.7368 - Train Accuracy: 0.6583 - Test Loss: 0.6600 - Test Accuracy: 0.7000\n",
      "Epoch 61/100 - Train Loss: 0.7509 - Train Accuracy: 0.6583 - Test Loss: 0.6657 - Test Accuracy: 0.7000\n",
      "Epoch 62/100 - Train Loss: 0.6880 - Train Accuracy: 0.6583 - Test Loss: 0.6293 - Test Accuracy: 0.7000\n",
      "Epoch 63/100 - Train Loss: 0.7515 - Train Accuracy: 0.6583 - Test Loss: 0.6688 - Test Accuracy: 0.7000\n",
      "Epoch 64/100 - Train Loss: 0.6254 - Train Accuracy: 0.6583 - Test Loss: 0.5567 - Test Accuracy: 0.7000\n",
      "Epoch 65/100 - Train Loss: 0.6094 - Train Accuracy: 0.6583 - Test Loss: 0.5414 - Test Accuracy: 0.7000\n",
      "Epoch 66/100 - Train Loss: 0.6061 - Train Accuracy: 0.6583 - Test Loss: 0.5405 - Test Accuracy: 0.7000\n",
      "Epoch 67/100 - Train Loss: 0.5941 - Train Accuracy: 0.6583 - Test Loss: 0.5269 - Test Accuracy: 0.7000\n",
      "Epoch 68/100 - Train Loss: 0.5985 - Train Accuracy: 0.6583 - Test Loss: 0.5295 - Test Accuracy: 0.7000\n",
      "Epoch 69/100 - Train Loss: 0.5899 - Train Accuracy: 0.6583 - Test Loss: 0.5273 - Test Accuracy: 0.7000\n",
      "Epoch 70/100 - Train Loss: 0.5895 - Train Accuracy: 0.6583 - Test Loss: 0.5223 - Test Accuracy: 0.7000\n",
      "Epoch 71/100 - Train Loss: 0.5827 - Train Accuracy: 0.6583 - Test Loss: 0.5212 - Test Accuracy: 0.7000\n",
      "Epoch 72/100 - Train Loss: 0.5858 - Train Accuracy: 0.6583 - Test Loss: 0.5188 - Test Accuracy: 0.7000\n",
      "Epoch 73/100 - Train Loss: 0.5764 - Train Accuracy: 0.6583 - Test Loss: 0.5134 - Test Accuracy: 0.7000\n",
      "Epoch 74/100 - Train Loss: 0.5837 - Train Accuracy: 0.6583 - Test Loss: 0.5168 - Test Accuracy: 0.7000\n",
      "Epoch 75/100 - Train Loss: 0.5717 - Train Accuracy: 0.6583 - Test Loss: 0.5072 - Test Accuracy: 0.7000\n",
      "Epoch 76/100 - Train Loss: 0.5737 - Train Accuracy: 0.6583 - Test Loss: 0.5070 - Test Accuracy: 0.7000\n",
      "Epoch 77/100 - Train Loss: 0.5681 - Train Accuracy: 0.6583 - Test Loss: 0.5013 - Test Accuracy: 0.7000\n",
      "Epoch 78/100 - Train Loss: 0.5753 - Train Accuracy: 0.6583 - Test Loss: 0.5081 - Test Accuracy: 0.7000\n",
      "Epoch 79/100 - Train Loss: 0.5655 - Train Accuracy: 0.6583 - Test Loss: 0.4981 - Test Accuracy: 0.7000\n",
      "Epoch 80/100 - Train Loss: 0.5688 - Train Accuracy: 0.6583 - Test Loss: 0.5022 - Test Accuracy: 0.7000\n",
      "Epoch 81/100 - Train Loss: 0.5631 - Train Accuracy: 0.6583 - Test Loss: 0.4981 - Test Accuracy: 0.7000\n",
      "Epoch 82/100 - Train Loss: 0.5694 - Train Accuracy: 0.6583 - Test Loss: 0.5037 - Test Accuracy: 0.7000\n",
      "Epoch 83/100 - Train Loss: 0.5615 - Train Accuracy: 0.6583 - Test Loss: 0.4988 - Test Accuracy: 0.7000\n",
      "Epoch 84/100 - Train Loss: 0.5643 - Train Accuracy: 0.6583 - Test Loss: 0.5000 - Test Accuracy: 0.7000\n",
      "Epoch 85/100 - Train Loss: 0.5583 - Train Accuracy: 0.6583 - Test Loss: 0.4908 - Test Accuracy: 0.7000\n",
      "Epoch 86/100 - Train Loss: 0.5586 - Train Accuracy: 0.6583 - Test Loss: 0.4925 - Test Accuracy: 0.7000\n",
      "Epoch 87/100 - Train Loss: 0.5581 - Train Accuracy: 0.6583 - Test Loss: 0.4993 - Test Accuracy: 0.7000\n",
      "Epoch 88/100 - Train Loss: 0.5569 - Train Accuracy: 0.6583 - Test Loss: 0.4920 - Test Accuracy: 0.7000\n",
      "Epoch 89/100 - Train Loss: 0.5552 - Train Accuracy: 0.6583 - Test Loss: 0.4960 - Test Accuracy: 0.7000\n",
      "Epoch 90/100 - Train Loss: 0.5554 - Train Accuracy: 0.6583 - Test Loss: 0.4919 - Test Accuracy: 0.7000\n",
      "Epoch 91/100 - Train Loss: 0.5519 - Train Accuracy: 0.6583 - Test Loss: 0.4912 - Test Accuracy: 0.7000\n",
      "Epoch 92/100 - Train Loss: 0.5552 - Train Accuracy: 0.6583 - Test Loss: 0.4933 - Test Accuracy: 0.7000\n",
      "Epoch 93/100 - Train Loss: 0.5495 - Train Accuracy: 0.6583 - Test Loss: 0.4890 - Test Accuracy: 0.7000\n",
      "Epoch 94/100 - Train Loss: 0.5532 - Train Accuracy: 0.6583 - Test Loss: 0.4917 - Test Accuracy: 0.7000\n",
      "Epoch 95/100 - Train Loss: 0.5465 - Train Accuracy: 0.6583 - Test Loss: 0.4841 - Test Accuracy: 0.7000\n",
      "Epoch 96/100 - Train Loss: 0.5536 - Train Accuracy: 0.6583 - Test Loss: 0.4931 - Test Accuracy: 0.7000\n",
      "Epoch 97/100 - Train Loss: 0.5442 - Train Accuracy: 0.6583 - Test Loss: 0.4819 - Test Accuracy: 0.7000\n",
      "Epoch 98/100 - Train Loss: 0.5464 - Train Accuracy: 0.6583 - Test Loss: 0.4858 - Test Accuracy: 0.7000\n",
      "Epoch 99/100 - Train Loss: 0.5418 - Train Accuracy: 0.6583 - Test Loss: 0.4828 - Test Accuracy: 0.7000\n",
      "Epoch 100/100 - Train Loss: 0.5460 - Train Accuracy: 0.6583 - Test Loss: 0.4869 - Test Accuracy: 0.7000\n",
      "Total Train Loss: 1.1906 - Total Train Accuracy: 0.5317 - Total Test Loss: 1.1138 - Total Test Accuracy: 0.5720\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "np.random.seed(0)\n",
    "import nnfs\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "nnfs.init()\n",
    "\n",
    "class LayerDense:\n",
    "    def __init__(self, n_inputs, n_neurons):\n",
    "        self.weights = 0.10 * np.random.randn(n_inputs, n_neurons)\n",
    "        self.biases = np.zeros((1, n_neurons))\n",
    "    def forward(self, inputs):\n",
    "        self.inputs = inputs\n",
    "        self.output = np.dot(inputs, self.weights) + self.biases\n",
    "    def backward(self, dvalues):\n",
    "        self.dweights = np.dot(self.inputs.T, dvalues)\n",
    "        self.dbiases = np.sum(dvalues, axis=0, keepdims=True)\n",
    "        self.dinputs = np.dot(dvalues, self.weights.T)\n",
    "\n",
    "class ActivationReLU:  \n",
    "    def forward(self, inputs):\n",
    "        self.inputs = inputs\n",
    "        self.output = np.maximum(0, inputs)\n",
    "    def backward(self, dvalues):\n",
    "        self.dinputs = dvalues.copy()\n",
    "        self.dinputs[self.inputs <= 0] = 0\n",
    "\n",
    "class LossMultiClassSVM:\n",
    "    def forward(self, scores, y):\n",
    "        num_classes = scores.shape[1]\n",
    "        num_examples = scores.shape[0]\n",
    "        correct_class_scores = scores[np.arange(num_examples), y]\n",
    "        margins = np.maximum(0, scores - correct_class_scores[:, np.newaxis] + 1.0)\n",
    "        margins[np.arange(num_examples), y] = 0\n",
    "        loss = np.sum(margins) / num_examples\n",
    "        self.dvalues = np.zeros_like(scores)\n",
    "        self.dvalues[margins > 0] = 1\n",
    "        incorrect_counts = np.sum(self.dvalues, axis=1)\n",
    "        self.dvalues[np.arange(num_examples), y] = -incorrect_counts\n",
    "        return loss\n",
    "\n",
    "class NeuralNetwork:\n",
    "    def __init__(self, layer_sizes):\n",
    "        self.layers = self.create_network(layer_sizes)\n",
    "        \n",
    "    def create_network(self, layer_sizes):\n",
    "        network = []\n",
    "        for i in range(1, len(layer_sizes)):\n",
    "            network.append(LayerDense(layer_sizes[i-1], layer_sizes[i]))\n",
    "            if i < len(layer_sizes) - 1:\n",
    "                network.append(ActivationReLU())\n",
    "        return network\n",
    "    \n",
    "    def forward(self, X):\n",
    "        for layer in self.layers:\n",
    "            layer.forward(X)\n",
    "            X = layer.output\n",
    "        return X\n",
    "    \n",
    "    def backward(self, dvalues):\n",
    "        for layer in reversed(self.layers):\n",
    "            layer.backward(dvalues)\n",
    "            dvalues = layer.dinputs\n",
    "    \n",
    "    def update_params(self, learning_rate):\n",
    "        for layer in self.layers:\n",
    "            if isinstance(layer, LayerDense):\n",
    "                layer.weights -= learning_rate * layer.dweights\n",
    "                layer.biases -= learning_rate * layer.dbiases\n",
    "\n",
    "def load_iris_dataset():\n",
    "    iris = load_iris()\n",
    "    X, y = iris.data, iris.target\n",
    "    return X, y\n",
    "\n",
    "def split_dataset(X, y, test_size=0.2, random_state=42):\n",
    "    return train_test_split(X, y, test_size=test_size, random_state=random_state)\n",
    "\n",
    "def calculate_accuracy(y_true, y_pred):\n",
    "    return np.mean(y_true == y_pred)\n",
    "\n",
    "def main():\n",
    "    X, y = load_iris_dataset()\n",
    "    X_train, X_test, y_train, y_test = split_dataset(X, y)\n",
    "    \n",
    "    num_features = X_train.shape[1]\n",
    "    num_classes = len(np.unique(y_train))\n",
    "\n",
    "    num_layers = int(input(\"Enter the number of layers: \"))\n",
    "    layer_neurons = [num_features]  # Input layer\n",
    "\n",
    "    for i in range(num_layers - 1):\n",
    "        neurons = int(input(f\"Enter the number of neurons in layer {i+1}: \"))\n",
    "        layer_neurons.append(neurons)\n",
    "\n",
    "    layer_neurons.append(num_classes)  # Output layer\n",
    "\n",
    "    neural_net = NeuralNetwork(layer_neurons)\n",
    "    loss_function = LossMultiClassSVM()\n",
    "    \n",
    "    num_epochs = int(input(\"Enter the number of epochs: \"))\n",
    "    learning_rate = float(input(\"Enter the learning rate: \"))\n",
    "\n",
    "    total_train_loss = 0.0\n",
    "    total_test_loss = 0.0\n",
    "    total_train_accuracy = 0.0\n",
    "    total_test_accuracy = 0.0\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        output_train = neural_net.forward(X_train)\n",
    "        train_loss = loss_function.forward(output_train, y_train)\n",
    "        train_accuracy = calculate_accuracy(y_train, np.argmax(output_train, axis=1))\n",
    "        \n",
    "        output_test = neural_net.forward(X_test)\n",
    "        test_loss = loss_function.forward(output_test, y_test)\n",
    "        test_accuracy = calculate_accuracy(y_test, np.argmax(output_test, axis=1))\n",
    "\n",
    "        print(f\"Epoch {epoch+1}/{num_epochs} - Train Loss: {train_loss:.4f} - Train Accuracy: {train_accuracy:.4f} - Test Loss: {test_loss:.4f} - Test Accuracy: {test_accuracy:.4f}\")\n",
    "\n",
    "        total_train_loss += train_loss\n",
    "        total_test_loss += test_loss\n",
    "        total_train_accuracy += train_accuracy\n",
    "        total_test_accuracy += test_accuracy\n",
    "\n",
    "        dvalues = loss_function.dvalues\n",
    "        neural_net.backward(dvalues)\n",
    "        neural_net.update_params(learning_rate)\n",
    "\n",
    "    total_train_loss /= num_epochs\n",
    "    total_test_loss /= num_epochs\n",
    "    total_train_accuracy /= num_epochs\n",
    "    total_test_accuracy /= num_epochs\n",
    "\n",
    "    print(f\"Total Train Loss: {total_train_loss:.4f} - Total Train Accuracy: {total_train_accuracy:.4f} - Total Test Loss: {total_test_loss:.4f} - Total Test Accuracy: {total_test_accuracy:.4f}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2df8c6e5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
